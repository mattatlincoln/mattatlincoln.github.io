{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Slides for Probability and Statistics module, 2016-2017\n",
    "# Matt Watkins, University of Lincoln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Markov Chains and Random Walks\n",
    "\n",
    "Markov Chains are named after [Andrey Markov](https://en.wikipedia.org/wiki/Andrey_Markov). \n",
    "\n",
    "They are a next step in the evaluation of probabilities \n",
    "\n",
    "- the probability of the next event in a sequence depends upon the previous event, but only the previous event.\n",
    "\n",
    "Contrast this with a purely random series of events where each event is independent. \n",
    "\n",
    "Most of what we've done up to now has dealt with independent events.\n",
    "\n",
    "This should be an example, [TSA](http://arstechnica.com/tech-policy/2016/04/tsa-spent-47000-on-an-app-that-just-randomly-picks-lanes-for-passengers/), would you want your chances of being checked depending on the person ahead of you in the queue?\n",
    "\n",
    "On the otherhand, clearly many real events do depend on what just happened \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    ">if it rains today will it rain tomorrow?\n",
    "\n",
    "[weather](http://weather.slimyhorror.com/),  \n",
    "[met office](http://www.metoffice.gov.uk/about-us/who/accuracy/forecasts),  \n",
    "[hoho](http://arstechnica.com/science/2016/04/accuweather-issues-90-day-forecasts-and-meteorologists-are-not-amused/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Content fillers\n",
    "\n",
    "A context you may have come across them is in generating text.\n",
    "\n",
    "There are reddit channels soley populated by bots \n",
    "[random content](https://www.reddit.com/r/SubredditSimulator/comments/3g9ioz/what_is_rsubredditsimulator/) (not all links guarenteed SFW)\n",
    "\n",
    "A little experimentation can generate a type of new content\n",
    "[Garkov](http://joshmillard.com/garkov/)  \n",
    "\n",
    "[The Big Markovski](http://joshmillard.com/markov/lebowski/?197312631)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And, of course,\n",
    "\n",
    "![](../Images/predictive_text.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Holmes in a nutshell\n",
    "\n",
    "[chapter 15 of Programming Pearls](https://tfetimes.com/wp-content/uploads/2015/04/ProgrammingPearls2nd.pdf):\n",
    "\n",
    ">A generator can make more interesting text by making each letter a random function of its predecessor. We could, therefore, read a sample text and count how many times every letter follows an A, how many times they follow a B, and so on for each letter of the alphabet. When we write the random text, we produce the next letter as a random function of the current letter. The Order-1 text was made by exactly this scheme:\n",
    ">>t I amy, vin. id wht omanly heay atuss n macon aresethe hired boutwhe t, tl, ad torurest t plur I wit hengamind tarer-plarody thishand.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    ">We can extend this idea to longer sequences of letters. The order-2 text was made by generating each letter as a function of the two letters preceding it (a letter pair is often called a digram). The digram TH, for instance, is often followed in English by the vowels A, E, I, O, U and Y, less frequently by R and W, and rarely by other letters.\n",
    "\n",
    ">>Ther I the heingoind of-pleat, blur it dwere wing waske hat trooss. Yout lar on wassing, an sit.\" \"Yould,\" \"I that vide was nots ther.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    ">The order-3 text is built by choosing the next letter as a function of the three previous letters (a trigram).\n",
    "\n",
    ">>I has them the saw the secorrow. And wintails on my my ent, thinks, fore voyager lanated the been elsed helder was of him a very free bottlemarkable,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    ">By the time we get to the order-4 text, most words are English, and you might not be surprised to learn that it was generated from a Sherlock Holmes story ( \"The Adventure of Abbey Grange'').\n",
    "\n",
    ">>His heard.\" \"Exactly he very glad trouble, and by Hopkins! That it on of the who difficentralia. He rushed likely?\" \"Blood night that.\n",
    "\n",
    "The text in Garkov strips is generated in exactly this way, but using words instead of letters. The input corpus is, as you'd expect, the text of many old Garfield strips."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Google Hegemony\n",
    "\n",
    "But Markov chains aren't just useful for automatically generating content parodies. They're also quite practical. You might even say Markov chains are a large part of what powers today's internet.  \n",
    "\n",
    "Markov chains underly, or at least are one way to understand, Google's trillion dollar PageRank formula:\n",
    "\n",
    ">The formula uses a model of a random surfer who gets bored after several clicks and switches to a random page. The PageRank value of a page reflects the chance that the random surfer will land on that page by clicking on a link. It can be understood as a Markov chain in which the states are pages, and the transitions, which are all equally probable, are the links between pages.\n",
    "\n",
    ">If a page has no links to other pages, it becomes a sink and therefore terminates the random surfing process. If the random surfer arrives at a sink page, it picks another URL at random and continues surfing again.\n",
    "\n",
    "from [wikipedia](https://en.wikipedia.org/wiki/PageRank#Simplified_algorithm)\n",
    "\n",
    "[Original paper here](http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What actually is a Markov Chain?\n",
    "\n",
    "so to be a bit more precise.\n",
    "\n",
    "- We have a set of states, $S = {s_1,s_2,\\ldots,s_n}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The process starts in one of those states and every **step**, it moves from one state to another. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If the chain is currently in state $s_i$ then it moves to state $s_j$ with probability $p_{ij}$.\n",
    "    - $p_{ij}$ only depends on the states $i$ and $j$ and not on the history of the chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**definition**\n",
    "\n",
    "The $p_{ij}$ are called transition probabilities. Note it is possible for the chain to remain in the same state, with probability $p_{ii}$.\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visual picture\n",
    "\n",
    "[visiualization of Markov Chains](http://setosa.io/ev/markov-chains/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transition Matrix\n",
    "\n",
    "> According to Kemeny, Snell, and Thompson, the Land of Oz is\n",
    "blessed by many things, but not by good weather. \n",
    "\n",
    ">>They never have two nice days in a row. If they have a nice day, they are just as likely to have snow as rain the\n",
    "next day. If they have snow or rain, they have an even chance of having the same\n",
    "the next day. If there is change from snow or rain, only half of the time is this a\n",
    "change to a nice day. \n",
    "\n",
    ">With this information we form a Markov chain as follows.\n",
    "We take as states the kinds of weather R, N, and S. From the above information\n",
    "we determine the transition probabilities. These are most conveniently represented\n",
    "in a square array as\n",
    "\n",
    "$$\n",
    "\\textbf{P} = \\left( \\matrix{\n",
    "         & \\text{R} & \\text{N} & \\text{S} \\cr\n",
    "\\text{R} &     1/2 &     1/4 &     1/4 \\cr\n",
    "\\text{N} &     1/2 &       0 &     1/2 \\cr\n",
    "\\text{S} &     1/4 &     1/4 &     1/2} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The rows of our matrix $\\mathbf{P}$ give the probabilities for the kinds of weather that follow R, N, or S.\n",
    "\n",
    "#### definition\n",
    "\n",
    "such a matrix, $\\mathbf{P}$, is called a transition, or stochastic matrix.\n",
    "\n",
    "It says if today is Rainy - so state $s_i = R$, we can transition to 1 of 3 new states:\n",
    "\n",
    "- R with probability $p_{RR} = 0.5$\n",
    "- N with probability $p_{RN} = 0.25$\n",
    "- S with probability $p_{RN} = 0.25$\n",
    "\n",
    "each row must sum to 1, we must end up in one of the states.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "intitial state vector: in general we can expect the initial state to be a mix of different $s_i$. \n",
    "\n",
    "#### definition \n",
    "\n",
    "The intitial state vector, $\\mathbf{u}$ ,is a probability vector which represents the starting distribution. \n",
    "\n",
    "The sum of the elements of $\\mathbf{u}$  must be 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**example**\n",
    "If today is a rainy day, what is the forecast for tomorrow?\n",
    "\n",
    "We have an initial state vector $\\textbf{u} = (1,0,0)$, then our forecast would be $\\textbf{uP}$\n",
    "\n",
    "$$\n",
    "(1,0,0) \\left( \\matrix{\n",
    " 1/2 &     1/4 &     1/4 \\cr\n",
    " 1/2 &       0 &     1/2 \\cr\n",
    " 1/4 &     1/4 &     1/2} \\right)\n",
    " = (1/2,1/4,1/4)\n",
    "$$\n",
    "\n",
    "in agreement with our expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Looking ahead\n",
    "\n",
    "We consider the question of determining the probability that, given the chain\n",
    "is in state $i$ today, it will be in state $j$ two days from now.  \n",
    "\n",
    "We denote this probability by $p_{ij}^{(2)}$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We look for the probability that, if it is _rainy_ today then it will be _snowy_ in two days time.\n",
    "\n",
    "The event that it is snowy two days from now is the disjoint union of the following three events:\n",
    "\n",
    "- it is rainy tomorrow and snowy two days from now,\n",
    "- it is nice tomorrow and snowy two days from now, \n",
    "- it is snowy tomorrow and snowy two days from now.  \n",
    "\n",
    "The probability of the first of these events is the product of the conditional probability that it is rainy tomorrow, given that it is rainy today, and the conditional probability that it is snowy two days from now, given that it is rainy tomorrow.  \n",
    "\n",
    "$$\n",
    "P(\\text{Snowy day 2 }|\\text{ Rainy day 1}) \\times P(\\text{Rainy day 1} | \\text{Rainy day 0})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using the transition matrix $\\textbf{P}$, we can write this product as\n",
    "$p_{11}p_{13}$.  \n",
    "\n",
    "$$\n",
    "\\textbf{P} = \\left( \\matrix{\n",
    "         & \\text{R} & \\text{N} & \\text{S} \\cr\n",
    "\\text{R} &     1/2 &     1/4 &     1/4 \\cr\n",
    "\\text{N} &     1/2 &       0 &     1/2 \\cr\n",
    "\\text{S} &     1/4 &     1/4 &     1/2} \\right)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The other two events \n",
    "\n",
    "- it is nice tomorrow and snowy two days from now, \n",
    "- it is snowy tomorrow and snowy two days from now.  \n",
    "\n",
    "also have probabilities that can be written as products of entries of $\\textbf{P}$.  \n",
    "\n",
    "Thus, we have\n",
    "\n",
    "$$p_{13}^{(2)} = p_{11}p_{13} + p_{12}p_{23} + p_{13}p_{33}\\ .$$\n",
    "\n",
    "This looks like the rule for matrix multiplication!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "More generally, the argument can be extended and we find\n",
    "\n",
    "**theorem**\n",
    "\n",
    "let $\\textbf{P}$ be the transition matrix of a Markov Chain. Then the $ij$th entry, $p_{ij}^{(n)}$, of the matrix $\\textbf{P}^{(n)}$ gives the probability that the Markov Chain stating in state $s_i$ will be in the state $s_j$ after $n$ moves.\n",
    "\n",
    "This can be worked out using matrix multiplication, as you've been doing in linear algebra.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Limiting\n",
    "\n",
    "Of particular interest would be the properties of the matrix $\\textbf{P}^{(n)}, n \\to \\infty$.\n",
    "\n",
    "Let's look at the Land of Oz example as we apply the  $\\textbf{P}$ matrix repeatedly\n",
    "\n",
    "![](../Images/P_to_the_n.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To get our n-day forecast we calculate, using an initial state vector $\\textbf{u} = (a,b,c)$, our forecast $\\textbf{u$^{(n)}$} = \\textbf{uP$^{(n)}$}$\n",
    "\n",
    "To get the long term behaviour of the system, we need to calculate $\\textbf{P}^{(n)}, n \\to \\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We see something very interesting if we look at $\\textbf{P}^{(6)}$\n",
    "\n",
    "![](../Images/P_to_the_6.png)\n",
    "\n",
    "all the rows have become the same. \n",
    "\n",
    "This means that no matter what initial state vector we start from, our forecast is the same!\n",
    "\n",
    "We will see that if we were to take a vector $\\textbf{w} = (0.4,0.2,0.4)$ then it would be stationary, or at equilibrium for long times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.4  0.2  0.4]\n",
      "[ 0.4  0.2  0.4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "w = [0.4,0.2,0.4]\n",
    "\n",
    "P = [[0.5, 0.25,0.25], [0.5, 0.0,0.5],[0.25,0.25,0.5]]\n",
    "Pn = [[0.4, 0.2,0.4], [0.4, 0.2,0.4],[0.4,0.2,0.4]]\n",
    "\n",
    "print(np.dot(w,Pn))\n",
    "print(np.dot(w,P))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This can be written $\\textbf{w} \\textbf{P} = \\textbf{w}$. \n",
    "\n",
    "This hints that by finding the eigenvectors and eigenvalues of $\\textbf{P}$ we'll be able to explore its long time behaviour."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
