
<!DOCTYPE html>
<html>
  <head>

    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />

    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

    <title>11 - Markov Chains and Random Walks - part 1 slides</title>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

    <!-- General and theme style sheets -->
    <link rel="stylesheet" href="../../../revealjs//css/reveal.css">
    <link rel="stylesheet" href="../../../revealjs//css/theme/beige.css" id="theme">

    <!-- If the query includes 'print-pdf', include the PDF print sheet -->
    <script>
      if( window.location.search.match( /print-pdf/gi ) ) {
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = '../../../revealjs//css/print/pdf.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
      }

    </script>

    <!--[if lt IE 9]>
	<script src="../../../revealjs//lib/js/html5shiv.js"></script>
	<![endif]-->

    <!-- Loading the mathjax macro -->
    <!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
      tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      processEnvironments: true
      },
      // Center justify equations in code and markdown cells. Elsewhere
      // we use CSS to left justify single line equations in code cells.
      displayAlign: 'center',
      "HTML-CSS": {
      styles: {'.MathJax_Display': {"margin": 0}},
      linebreaks: { automatic: true }
      }
      });
    </script>
    <!-- End of mathjax configuration -->

    <!-- Get Font-awesome from cdn -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.1.0/css/font-awesome.css">

    <!-- Custom stylesheet, it must be in the same directory as the html file -->
    <link rel="stylesheet" href="../custom.css">

  </head>
  
  <body>

    <div class="reveal">
      <div class="slides">
	<section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <h1 id="Markov-Chains-and-Random-Walks">Markov Chains and Random Walks<a class="anchor-link" href="#Markov-Chains-and-Random-Walks">&#182;</a></h1><p>Markov Chains are named after <a href="https://en.wikipedia.org/wiki/Andrey_Markov">Andrey Markov</a>.</p>
		  <p>They are a next step in the evaluation of probabilities</p>
		  <ul>
		    <li>the probability of the next event in a sequence depends upon the previous event, but only the previous event.</li>
		  </ul>
		  <p>Contrast this with a purely random series of events where each event is independent.</p>
		  <p>Most of what we've done up to now has dealt with independent events.</p>
		  <p>This should be an example, <a href="http://arstechnica.com/tech-policy/2016/04/tsa-spent-47000-on-an-app-that-just-randomly-picks-lanes-for-passengers/">TSA</a>, would you want your chances of being checked depending on the person ahead of you in the queue?</p>
		  <p>On the otherhand, clearly many real events do depend on what just happened</p>

		</div>
	      </div>
	</div></section></section><section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <blockquote><p>if it rains today will it rain tomorrow?</p>
		  </blockquote>
		  <p><a href="https://weather.slimyhorror.com/">weather</a>,<br>
		    <a href="https://www.metoffice.gov.uk/about-us/who/accuracy/forecasts">met office</a>,<br>
		    <a href="https://arstechnica.com/science/2016/04/accuweather-issues-90-day-forecasts-and-meteorologists-are-not-amused/">hoho</a></p>

		</div>
	      </div>
	</div></section></section><section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <h2 id="Content-fillers">Content fillers<a class="anchor-link" href="#Content-fillers">&#182;</a></h2><p>A context you may have come across them is in generating text.</p>
		  <p>There are reddit channels soley populated by bots 
		    <a href="https://www.reddit.com/r/SubredditSimulator/comments/3g9ioz/what_is_rsubredditsimulator/">random content</a> (not all links guarenteed SFW)</p>
		  <p>A little experimentation can generate <a href="http://joshmillard.com/garkov/">Garkov</a>, improved Garfield comic strips</p>
		  <p><a href="https://joshmillard.com/markov/lebowski/?197312631">The Big Markovski</a></p>

		</div>
	      </div>
	    </div><div class="fragment">
	      <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
		</div>
		<div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		  <div class="text_cell_render border-box-sizing rendered_html">
		    <p>And, of course,</p>
		    <p><img src="../Images/predictive_text.jpg" alt="Predictive text"></p>

		  </div>
		</div>
	</div></div></section></section><section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <h2 id="Holmes-in-a-nutshell">Holmes in a nutshell<a class="anchor-link" href="#Holmes-in-a-nutshell">&#182;</a></h2><p><a href="https://tfetimes.com/wp-content/uploads/2015/04/ProgrammingPearls2nd.pdf">chapter 15 of Programming Pearls</a>:</p>
		  <blockquote><p>A generator can make more interesting text by making each letter a random function of its predecessor. We could, therefore, read a sample text and count how many times every letter follows an A, how many times they follow a B, and so on for each letter of the alphabet. When we write the random text, we produce the next letter as a random function of the current letter. The Order-1 text was made by exactly this scheme:</p>
		    <blockquote><p>t I amy, vin. id wht omanly heay atuss n macon aresethe hired boutwhe t, tl, ad torurest t plur I wit hengamind tarer-plarody thishand.</p>
		    </blockquote>
		  </blockquote>

		</div>
	      </div>
	  </div></section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <blockquote><p>We can extend this idea to longer sequences of letters. The order-2 text was made by generating each letter as a function of the two letters preceding it (a letter pair is often called a digram). The digram TH, for instance, is often followed in English by the vowels A, E, I, O, U and Y, less frequently by R and W, and rarely by other letters.</p>
		    <blockquote><p>Ther I the heingoind of-pleat, blur it dwere wing waske hat trooss. Yout lar on wassing, an sit." "Yould," "I that vide was nots ther.</p>
		    </blockquote>
		  </blockquote>

		</div>
	      </div>
	  </div></section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <blockquote><p>The order-3 text is built by choosing the next letter as a function of the three previous letters (a trigram).</p>
		    <blockquote><p>I has them the saw the secorrow. And wintails on my my ent, thinks, fore voyager lanated the been elsed helder was of him a very free bottlemarkable,</p>
		    </blockquote>
		  </blockquote>

		</div>
	      </div>
	  </div></section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <blockquote><p>By the time we get to the order-4 text, most words are English, and you might not be surprised to learn that it was generated from a Sherlock Holmes story ( "The Adventure of Abbey Grange").</p>
		    <blockquote>
		      <p>His heard." "Exactly he very glad trouble, and by Hopkins! That it on of the who difficentralia. He rushed likely?" "Blood night that.</p>
		    </blockquote>
		  </blockquote>

		  <p>The text in Garkov strips is generated in exactly this way, but using words instead of letters. The input corpus is, as you'd expect, the text of many old Garfield strips.</p>

		</div>
	      </div>
	</div></section></section><section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <h2 id="Google-Hegemony">Google Hegemony<a class="anchor-link" href="#Google-Hegemony">&#182;</a></h2><p>But Markov chains aren't just useful for automatically generating content parodies. They're also quite practical. You might even say Markov chains are a large part of what powers today's internet.</p>
		  <p>Markov chains underly, or at least are one way to understand, Google's trillion dollar PageRank formula:</p>
		  <blockquote><p>The formula uses a model of a random surfer who gets bored after several clicks and switches to a random page. The PageRank value of a page reflects the chance that the random surfer will land on that page by clicking on a link. It can be understood as a Markov chain in which the states are pages, and the transitions, which are all equally probable, are the links between pages.</p>
		    <p>If a page has no links to other pages, it becomes a sink and therefore terminates the random surfing process. If the random surfer arrives at a sink page, it picks another URL at random and continues surfing again.</p>
		  </blockquote>
		  <p>from <a href="https://en.wikipedia.org/wiki/PageRank#Simplified_algorithm">wikipedia</a></p>
		  <p><a href="https://ilpubs.stanford.edu:8090/422/1/1999-66.pdf">Original paper here</a>.</p>

		</div>
	      </div>
	</div></section></section><section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <h2 id="What-actually-is-a-Markov-Chain?">What actually is a Markov Chain?<a class="anchor-link" href="#What-actually-is-a-Markov-Chain?">&#182;</a></h2><p>so to be a bit more precise.</p>
		  <ul>
		    <li>We have a set of states, $S = {s_1,s_2,\ldots,s_n}$. </li>
		  </ul>

		</div>
	      </div>
	    </div><div class="fragment">
	      <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
		</div>
		<div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		  <div class="text_cell_render border-box-sizing rendered_html">
		    <ul>
		      <li>The process starts in one of those states and every <strong>step</strong>, it moves from one state to another. </li>
		    </ul>

		  </div>
		</div>
	    </div></div><div class="fragment">
	      <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
		</div>
		<div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		  <div class="text_cell_render border-box-sizing rendered_html">
		    <ul>
		      <li>If the chain is currently in state $s_i$ then it moves to state $s_j$ with probability $p_{ij}$.<ul>
			  <li>$p_{ij}$ only depends on the states $i$ and $j$ and not on the history of the chain</li>
			</ul>
		      </li>
		    </ul>

		  </div>
		</div>
	    </div></div><div class="fragment">
	      <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
		</div>
		<div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		  <div class="text_cell_render border-box-sizing rendered_html">
		    <p><strong>definition</strong></p>
		    <p>The $p_{ij}$ are called transition probabilities. Note it is possible for the chain to remain in the same state, with probability $p_{ii}$.</p>
		  </div>
		</div>
	</div></div></section></section>
	<section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <h2 id="Visual-picture1">Visual picture<a class="anchor-link" href="#Visual-picture">&#182;</a></h2>
		  <a href="http://setosa.io/ev/markov-chains/">Nice animations and explanation here!</a>
		</div>
	      </div>
	</div></section></section>
	<section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <h2 id="Transition-Matrix">Transition Matrix<a class="anchor-link" href="#Transition-Matrix">&#182;</a></h2><blockquote><p>According to Kemeny, Snell, and Thompson, the Land of Oz is
		      blessed by many things, but not by good weather.</p>
		    <blockquote>
		      <p>They never have two nice days in a row. If they have a nice day, they are just as likely to have snow as rain the
			next day. If they have snow or rain, they have an even chance of having the same
			the next day. If there is change from snow or rain, only half of the time is this a
			change to a nice day.
		      </p>
		    </blockquote>
		  </blockquote>

		</div>
	      </div>
	  </div></section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <p>
		    <blockquote>
		      <p>They never have two nice days in a row. If they have a nice day, they are just as likely to have snow as rain the
			next day. If they have snow or rain, they have an even chance of having the same
			the next day. If there is change from snow or rain, only half of the time is this a
			change to a nice day.
		      </p>
		    </blockquote>
		  </p>
		  <p>With this information we form a Markov chain as follows.
		    We take as states the kinds of weather R, N, and S. From the above information
		    we determine the transition probabilities. These are most conveniently represented
		    in a square array as</p>
		  <p>$$
		    \textbf{P} = \left( \matrix{
		    &amp; \text{R} &amp; \text{N} &amp; \text{S} \cr
		    \text{R} &amp;     1/2 &amp;     1/4 &amp;     1/4 \cr
		    \text{N} &amp;     1/2 &amp;       0 &amp;     1/2 \cr
		    \text{S} &amp;     1/4 &amp;     1/4 &amp;     1/2} \right)
		    $$</p>
		</div>
	      </div>
	    </div>
	  </section>
	  <section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <p>The rows of our matrix $\mathbf{P}$ give the probabilities for the kinds of weather that follow R, N, or S.</p>
		  <h4 id="definition">definition<a class="anchor-link" href="#definition">&#182;</a></h4><p>such a matrix, $\mathbf{P}$, is called a transition, or stochastic matrix.</p>
		  <p>It says if today is Rainy - so state $s_i = R$, we can transition to 1 of 3 new states:</p>
		  <ul>
		    <li>R with probability $p_{RR} = 0.5$</li>
		    <li>N with probability $p_{RN} = 0.25$</li>
		    <li>S with probability $p_{RN} = 0.25$</li>
		  </ul>
		  <p>each row must sum to 1, we must end up in one of the states.</p>
		  
		</div>
	      </div>
	    </div>
	  </section>
	  <section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <h4 id="definition">definition<a class="anchor-link" href="#definition">&#182;</a></h4>
		  <p>The initial state vector, $\mathbf{u}$ ,is a probability vector which represents the starting distribution.</p>
		  <p>The sum of the elements of $\mathbf{u}$  must be 1.</p>
		</div>
	      </div>
	    </div>
	  </section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <p><strong>example</strong>
		    If today is a rainy day, what is the forecast for tomorrow?</p>
		  <p>We have an initial state vector $\textbf{u} = (1,0,0)$, then our forecast would be $\textbf{uP}$</p>
		  <p>$$
		    (1,0,0) \left( \matrix{
		    1/2 &amp;     1/4 &amp;     1/4 \cr
		    1/2 &amp;       0 &amp;     1/2 \cr
		    1/4 &amp;     1/4 &amp;     1/2} \right)
		    = (1/2,1/4,1/4)
		    $$</p>
		  <p>in agreement with our expectations</p>

		</div>
	      </div>
	</div></section></section><section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <h2 id="Visual-picture">Visual picture of a Markov Chain<a class="anchor-link" href="#Visual-picture-again">&#182;</a></h2>
		  <a href='http://setosa.io/markov/index.html#%7B%22tm%22%3A%5B%5B0.5%2C0.25%2C0.25%5D%2C%5B0.5%2C0%2C0.5%5D%2C%5B0.25%2C0.25%2C0.5%5D%5D%7D'>Visual-picture of the transition matrix</a>
		</div>
		<p>You can adjust the chain by providing a valid transition matrix. This should be specified as a valid 2D python array (note the double [[ and ]] at beginning and end).</p>
	      </div>
	</div></section></section><section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <h2 id="Looking-ahead">Looking ahead<a class="anchor-link" href="#Looking-ahead">&#182;</a></h2><p>We consider the question of determining the probability that, given the chain
		    is in state $i$ today, it will be in state $j$ two days from now.</p>
		  <p>We denote this probability by $p_{ij}^{(2)}$.</p>

		</div>
	      </div>
	  </div></section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <p>We look for the probability that, if it is <em>rainy</em> today then it will be <em>snowy</em> in two days time.</p>
		  <p>The event that it is snowy two days from now is the disjoint union of the following three events:</p>
		  <ul>
		    <li>it is rainy tomorrow and snowy two days from now,</li>
		    <li>it is nice tomorrow and snowy two days from now, </li>
		    <li>it is snowy tomorrow and snowy two days from now.  </li>
		  </ul>
		  <p>The probability of the first of these events is the product of the conditional probability that it is rainy tomorrow, given that it is rainy today, and the conditional probability that it is snowy two days from now, given that it is rainy tomorrow.</p>
		  <p>$$
		    P(\text{Snowy day 2 }|\text{ Rainy day 1}) \times P(\text{Rainy day 1} | \text{Rainy day 0})
		    $$</p>

		</div>
	      </div>
	  </div></section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <p>Using the transition matrix $\textbf{P}$, we can write this product as
		    $p_{11}p_{13}$.</p>
		  <p>$$
		    \textbf{P} = \left( \matrix{
		    &amp; \text{R} &amp; \text{N} &amp; \text{S} \cr
		    \text{R} &amp;     1/2 &amp;     1/4 &amp;     1/4 \cr
		    \text{N} &amp;     1/2 &amp;       0 &amp;     1/2 \cr
		    \text{S} &amp;     1/4 &amp;     1/4 &amp;     1/2} \right)
		    $$</p>

		</div>
	      </div>
	  </div></section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <p>The other two events</p>
		  <ul>
		    <li>it is nice tomorrow and snowy two days from now, </li>
		    <li>it is snowy tomorrow and snowy two days from now.  </li>
		  </ul>
		  <p>also have probabilities that can be written as products of entries of $\textbf{P}$.</p>
		  <p>Thus, we have</p>
		  <p>$$p_{13}^{(2)} = p_{11}p_{13} + p_{12}p_{23} + p_{13}p_{33}\ .$$</p>
		  <p>This looks like the rule for matrix multiplication!</p>

		</div>
	      </div>
	  </div></section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <p>More generally, the argument can be extended and we find</p>
		  <p><strong>theorem</strong></p>
		  <p>let $\textbf{P}$ be the transition matrix of a Markov Chain. Then the $ij$th entry, $p_{ij}^{(n)}$, of the matrix $\textbf{P}^{(n)}$ gives the probability that the Markov Chain stating in state $s_i$ will be in the state $s_j$ after $n$ moves.</p>
		  <p>This can be worked out using matrix multiplication, as you've been doing in linear algebra.</p>

		</div>
	      </div>
	</div></section></section><section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <h3 id="Limiting">Limiting<a class="anchor-link" href="#Limiting">&#182;</a></h3><p>Of particular interest would be the properties of the matrix $\textbf{P}^{(n)}, n \to \infty$.</p>
		  <p>Let's look at the Land of Oz example as we apply the  $\textbf{P}$ matrix repeatedly</p>
		  <p><img src="../Images/P_to_the_n.png" alt=""></p>

		</div>
	      </div>
	</div></section></section><section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <p>To get our n-day forecast we calculate, using an initial state vector $\textbf{u} = (a,b,c)$, our forecast $\textbf{u$^{(n)}$} = \textbf{uP$^{(n)}$}$</p>
		  <p>To get the long term behaviour of the system, we need to calculate $\textbf{P}^{(n)}, n \to \infty$.</p>

		</div>
	      </div>
	</div></section></section>

	<section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <p>We see something very interesting if we look at $\textbf{P}^{(6)}$</p>
		  <p><img src="../Images/P_to_the_6.png" alt=""></p>
		  <p>all the rows have become the same.</p>
		  <p>This means that no matter what initial state vector we start from, our forecast is the same!</p>
		  <p>We will see that if we were to take a vector $\textbf{w} = (0.4,0.2,0.4)$ then it would be stationary, or at equilibrium for long times.</p>

		</div>
	      </div>
	    </div>
	  </section>

	  <section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <p>This can be written $\textbf{w} \textbf{P} = \textbf{w}$.</p>
		  <p>This hints that by finding the eigenvectors and eigenvalues of $\textbf{P}$ we'll be able to explore its long time behaviour.</p>

		</div>
	      </div>
	</div></section></section>

	<section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <h2 id="Types-of-Marokov-Chain">Types of Marokov Chain<a class="anchor-link" href="#Types-of-Marokov-Chain">&#182;</a></h2><p>there are actually several types of Markov chain that can be categorized by the properties of their transition matrices. Their properties are qualitatively different in the long term.</p>
		  <p>We'll only look at</p>
		  <ul>
		    <li>Absorbing chains</li>
		    <li>Ergodic Chains<ul>
			<li>Regular Chains</li>
		      </ul>
		    </li>
		  </ul>

		</div>
	      </div>
	</div></section></section><section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <h2 id="Absorbing-Markov-Chains">Absorbing Markov Chains<a class="anchor-link" href="#Absorbing-Markov-Chains">&#182;</a></h2><p><strong>definition</strong></p>
		  <p>a Markov Chain is called absorbing if it has at least one state $s_i$ that is impossible to leave, $p_{ii} = 1$, and it is possible to reach an absorbing state from every state.</p>
		  <p><strong>definition</strong></p>
		  <p>states with $p_{ii} = 1$ are called absorbing states. Other states are called <em>transient states</em>.</p>

		</div>
	      </div>
	</div></section></section><section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <p><strong>Example</strong></p>
		  <p>A man walks along a four-block stretch of Park Avenue.</p>
		  <p>If he is at corner 1, 2, or 3, then he walks to the left or right with equal
		    probability.</p>
		  <p>He continues until he reaches corner 4, which is a bar, or corner 0, which is his home.</p>
		  <p>If he reaches either home or the bar, he stays there.</p>
		  <p><img src="PSfig11-3.png" alt=""></p>

		</div>
	      </div>
	  </div></section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <p>We form a Markov chain with states 0, 1, 2, 3, and 4.  States 0 and 4 are
		    absorbing states.</p>
		  <p>The transition matrix is then</p>
		  <p>$$
		    \textbf{P} =\begin{matrix}
		    &amp;  0  &amp;  1  &amp;  2  &amp;  3  &amp;  4  \cr
		    0 &amp;  1  &amp;  0  &amp;  0  &amp;  0  &amp;  0  \cr
		    1 &amp; 1/2 &amp;  0  &amp; 1/2 &amp;  0  &amp;  0  \cr
		    2 &amp;  0  &amp; 1/2 &amp;  0  &amp; 1/2 &amp;  0  \cr
		    3 &amp;  0  &amp;  0  &amp; 1/2 &amp;  0  &amp; 1/2 \cr
		    4 &amp;  0  &amp;  0  &amp;  0  &amp;  0  &amp;  1 \cr \end{matrix}
		    $$
		    The states 1, 2, and 3 are transient states, and from any of these
		    it is possible to reach the absorbing states 0 and 4.</p>
		  <p>The chain is an absorbing chain.  When a process reaches an absorbing state, we shall say that
		    it is absorbed.</p>

		</div>
	      </div>
	  </div></section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <h1 id="Markov-Chain-diagrams">Markov Chain diagrams<a class="anchor-link" href="#Markov-Chain-diagrams">&#182;</a></h1><p>it can be useful to depict a Markov Chain in diagramatic form.</p>
		  <p>For instance for the Drunkard's walk we had</p>
		  <p><img src="PSfig11-3.png" alt=""></p>
		  <p>the nodes show the states, $s_j$, whilst the arrows show the transition probabilities, $p_{ij}$.</p>
		  <p>The diagrams make it easy to spot absorbing states, here the two end states, which have no arrows heading back to other states.</p>

		</div>
	      </div>
	    </div><div class="fragment">
	      <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
		</div>
		<div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		  <div class="text_cell_render border-box-sizing rendered_html">
		    <h2 id="Visual-picture">Visual picture<a class="anchor-link" href="#Visual-picture">&#182;</a></h2><p>you can make these diagrams prettier</p>
		    <p><a href="https://setosa.io/markov/index.html#%7B%22tm%22%3A%5B%5B1%2C0%2C0%2C0%2C0%5D%2C%5B0.5%2C0%2C0.5%2C0%2C0%5D%2C%5B0%2C0.5%2C0%2C0.5%2C0%5D%2C%5B0%2C0%2C0.5%2C0%2C0.5%5D%2C%5B0%2C0%2C0%2C0%2C1%5D%5D%7D">visiualization of Markov Chains</a></p>

		  </div>
		</div>
	</div></div></section></section><section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <p><strong>example</strong></p>
		  <p>example of an absorbing Markov chain</p>
		  <p><img style="width:400px" src="https://s-media-cache-ak0.pinimg.com/736x/03/c3/ab/03c3ab693eedcd84c1119a947974cb93.jpg" alt=""></p>

		</div>
	      </div>
	  </div></section>
	  <section>
	      <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
		</div>
		<div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		  <div class="text_cell_render border-box-sizing rendered_html">
		    <p>The 100 is absorbing (in the sense the game ends at that point). The other tiles are transient states.</p>
		    <p>It is quite possible to set up and solve this, finding the tiles that most time is spent on etc.</p>
		    <p><a href="https://www.datagenetics.com/blog/november12011/">snakes and ladders analysed</a></p>

		  </div>
	    </div></div></section><section>
	      <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
		</div>
		<div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		  <div class="text_cell_render border-box-sizing rendered_html">
		    <iframe src="https://trinket.io/embed/python3/4e7e7bbd64" width="100%" height="500" frameborder="0" marginwidth="0" marginheight="0" allowfullscreen></iframe>
		    <p>You can change the `rolls` variable to simulate longer and longer games. The shading of the squares shows the probability of being at that square after the given number of rolls.</p>
		</div>
	  </div></div></section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <h2 id="Canonical-Form">Canonical Form<a class="anchor-link" href="#Canonical-Form">&#182;</a></h2><p>If we rearrange the transition matrix for an absorbing chain so that the transient states are first, followed by the absorbing states we get the so called canonical form, which will have the general form</p>
		  <p><img src="../Images/absorb_I.png" alt=""></p>

		</div>
	      </div>
	    </div><div class="fragment">
	      <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
		</div>
		<div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		  <div class="text_cell_render border-box-sizing rendered_html">
		    <p>and it can be shown that it retains the same block structure when raised to the power $n$. We can extract the answers to the questions from the matrices $\mathbf{Q}$ and $\mathbf{R}$:</p>
		    <ul>
		      <li>What is the  probability that the process will eventually reach an absorbing state?</li>
		      <li>What is the probability that the process will end up in a given absorbing state?</li>
		      <li>On the average, how long will it take for the process to be absorbed?</li>
		      <li>On the average, how many times will the process be in each transient state?  </li>
		    </ul>
		    <p>The answers to all these questions depend, in general, on the
		      state from which the process starts as well as the transition probabilities.</p>
		  </div>
		</div>
	</div></div></section></section><section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <h2 id="Ergodic-Markov-Chains">Ergodic Markov Chains<a class="anchor-link" href="#Ergodic-Markov-Chains">&#182;</a></h2><h4 id="definition">definition<a class="anchor-link" href="#definition">&#182;</a></h4><p>A Markov chain is called an ergodic chain if it is possible to go from every state to every state (though this can be in several moves).</p>
		  <h4 id="definition">definition<a class="anchor-link" href="#definition">&#182;</a></h4><p>A Markov chain is called a regular chain if some power of the transition matrix has only positive elements.</p>
		  <p>Every regular chain is ergodic, but not all ergodic chains are regular.</p>

		</div>
	      </div>
	</div></section></section><section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <h3 id="Long-time-behaviour">Long time behaviour<a class="anchor-link" href="#Long-time-behaviour">&#182;</a></h3><p>Regular Markov chains have a well defined long term behaviour</p>
		  <p><strong>theorem</strong>
		    Let $\textbf{P}$ is the transition matrix from a regular chain. Then, as $n \to \infty$, the powers $\textbf{P$^{(n)}$}$ approach a limiting matrix $\textbf{W}$ with all rows the same vector $\textbf{w}$.</p>
		  <p>If we look at our Land of Oz example we can see this in action</p>

		</div>
	      </div>
	  </div></section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <iframe src="https://trinket.io/embed/python3/a7491a9b82" width="100%" height="600" frameborder="0" marginwidth="0" marginheight="0" allowfullscreen></iframe>
		</div>
	      </div>
	  </div></section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <p>If this vector $\textbf{w}$ is a steady state of the chain then we should have that $\textbf{w} \textbf{P} = \textbf{w}\lambda$.</p>
		  <p>In fact we have that $\textbf{w} \textbf{P} = \textbf{wI}$, where $\textbf{I}$ is an identity matrix, because we need to preserve the amount of probability</p>
		  <p>We can find $\textbf{w}$ by linear algebra techniques:</p>
		  <ul>
		    <li>find the eigenvalues/vectors of $\textbf{P}$</li>
		    <li>directly solve $\textbf{w} \textbf{P} = \textbf{wI}$, as we know that we want the eigenvector with eigenvalue 1.</li>
		  </ul>

		</div>
	      </div>
	</div></section></section><section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <h2 id="Random-Walks">Random Walks<a class="anchor-link" href="#Random-Walks">&#182;</a></h2><p>random walks can occur in spaces with various dimensions. The simplest ones work with a fixed step.</p>
		  <p>We've seen one, in 1D - the difference between the number of heads and tails thrown when a coin is repeatedly tossed</p>
		  <ul>
		    <li>at each step the walker can move up, with probability $p$, or down, with probability $1-p$ the number line</li>
		  </ul>
		  <p>In 2D (on a regular grid)</p>
		  <ul>
		    <li>at each step the walker can move to one of the eight neighbouring sites</li>
		  </ul>
		  <p>In 3D (on a regular grid) we have something rather similar to diffusion</p>
		  <ul>
		    <li>at each step the walker can move to one of the 9 + 8 + 9 = 26 neighbouring sites</li>
		  </ul>

		</div>
	      </div>
	  </div></section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <p>Interestingly, there are qualitative differences between the walks in 1 and 2 or 3 dimensions.</p>
		  <ul>
		    <li>It can be proved that in 1 or 2 D the walker will always return to its starting point.</li>
		    <li>In 3D the walker may never return (probability of return is approximately only 1/3)</li>
		  </ul>
		  <p>Grinstead and Snell sum this up as</p>
		  <blockquote><p>"One may summarize these results by stating that one should not get drunk in more than two dimensions."</p>
		  </blockquote>

		</div>
	      </div>
	</div></section></section><section><section>
	    <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
	      </div>
	      <div class="inner_cell" style='background:rgba(255,255,255,0.9)'>
		<div class="text_cell_render border-box-sizing rendered_html">
		  <h1 id="Summary">Summary<a class="anchor-link" href="#Summary">&#182;</a></h1><ul>
		    <li>describe the evolution between a series of states</li>
		    <li>Markov Chains depend on the current state, but not previous history</li>
		    <li>Initial state vector defines how the chain starts</li>
		    <li>Transition matrix (often called the stochastic matrix) built from  the transition probabilities between states</li>
		    <li>evolution occurs by applying the transition matrix repeatedly - each application is a step</li>
		    <li>use methods of linear algebra to explore long time properties of the chains</li>
		  </ul>

		</div>
	      </div>
	</div></section></section>
	
      </div>
    </div>

    <script>

      require(
      {
      // it makes sense to wait a little bit when you are loading
      // reveal from a cdn in a slow connection environment
      waitSeconds: 15
      },
      [
      "../../../revealjs//lib/js/head.min.js",
      "../../../revealjs//js/reveal.js"
      ],

      function(head, Reveal){

      // Full list of configuration options available here: https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
      controls: true,
      progress: true,
      history: true,
      // Parallax background image
      parallaxBackgroundImage: '../Images/dice.jpg',
      //Parallax background size
      parallaxBackgroundSize: '1920px 1280px', // CSS syntax, e.g. "2100px 900px

      theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
      transition: Reveal.getQueryHash().transition || 'linear', // default/cube/page/concave/zoom/linear/none

      // Optional libraries used to extend on reveal.js
      dependencies: [
      { src: "../../../revealjs//lib/js/classList.js",
      condition: function() { return !document.body.classList; } },
      { src: "../../../revealjs//plugin/notes/notes.js",
      async: true,
      condition: function() { return !!document.body.classList; } }
      ]
      });

      var update = function(event){
      if(MathJax.Hub.getAllJax(Reveal.getCurrentSlide())){
      MathJax.Hub.Rerender(Reveal.getCurrentSlide());
      }
      };

      Reveal.addEventListener('slidechanged', update);

      var update_scroll = function(event){
      $(".reveal").scrollTop(0);
      };

      Reveal.addEventListener('slidechanged', update_scroll);

      }
      );
    </script>

  </body>


</html>
