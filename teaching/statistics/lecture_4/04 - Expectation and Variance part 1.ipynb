{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Slides for Probability and Statistics module, 2015-2016\n",
    "# Matt Watkins, University of Lincoln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Expectation and Variance\n",
    "\n",
    "In these lectures we will define the expectation and variance of a random variable. \n",
    "\n",
    "This is a further step in connecting abstract probability distribututions to statistical measures, and the real world, if required.\n",
    "\n",
    "<div style=\"background-color:Gold; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left: 8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;\">\n",
    "By the end of the lecture you should know \n",
    "<li> how to calculate the expectation value of a random variable (this is some measure of where the centre of a distribution is) </li>\n",
    "<li> how to calculate the variance of a random variable (this is a measure of how widely spread a distribution is).</li>\n",
    "<li> how to calculate expectation values of a function of a random variable.</li>\n",
    "</div>\n",
    "\n",
    "Later we'll study particular probability distributions and understanding their expectation values will allow us to model and predict the results of measurements made on objects that can be modelled as random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Revision\n",
    "\n",
    "## Discrete random variables\n",
    "\n",
    "**Definition**\n",
    "Consider an experiment, with outcome set $S$, split into $n$ mutually exclusive and exhaustive events $E_1,E_2,E_3,\\ldots,E_n$. A variable, $X$ say, which can assume exactly $n$ numerical values each of which corresponds to one and only one of the given events is called a random variable.\n",
    "\n",
    "Schematically the mutually exclusive and exhaustive events look like\n",
    "\n",
    "<img src=\"../Images/Exclusive_and_exhaustive.jpg\" alt=\"Exhaustive\" height=\"200\" width=\"200\">\n",
    "\n",
    "Here our outcome set is split into 4 mutually exclusive events (no overlap) and exhaustive (all of $S$ is covered by them). \n",
    "\n",
    "So to associate a random variable (call it $X$) with this sample space we could have something like where to each mutually exclusive event we associate a value of $X = x$ and a probability $p_X(x)$. \n",
    "\n",
    "|$X$|event|$p_X(x)$|\n",
    "|-|-|-|\n",
    "|1|$E_1$|$p_X(1) = 0.1$|\n",
    "|2|$E_2$|$p_X(2) = 0.2$|\n",
    "|3|$E_3$|$p_X(3) = 0.3$|\n",
    "|4|$E_4$|$p_X(4) = 0.4$|\n",
    "\n",
    "Check list\n",
    "- is the sample space well defined?\n",
    "- are the events mutually exclusive?\n",
    "- do the events cover all the sample space?\n",
    "- are values of the variable clearly assigned one-to-one to the possible events?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Expectation of a Random variable\n",
    "\n",
    "**Definition**\n",
    "\n",
    "Given a random variable $X$ with a probability mass function $p(x)$  we define the expectation of $X$, written as $\\text{E}[X]$ as \n",
    "\n",
    "<div style=\"background-color:Gold; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left: 8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;\">\n",
    "$$\n",
    "\\text{E}[X] = \\sum_{x\\in X} x \\cdot p(x)\n",
    "$$\n",
    "</div>\n",
    "\n",
    "The equivalent for a continuous random variable $Z$ is\n",
    "\n",
    "<div style=\"background-color:Gold; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left: 8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;\">\n",
    "$$\n",
    "\\text{E}[Z] = \\int_{-\\infty}^{\\infty} z\\cdot f(z) \\mathrm{d}z\n",
    "$$\n",
    "</div>\n",
    "\n",
    "We see that the relationship is very close between discrete and continuous cases - we replace a sum with an integral.\n",
    "\n",
    "<div style=\"background-color:Gold; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left: 8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;\">\n",
    "We also call $\\text{E}[X]$ the mean of $X$ and write it as $\\mu_X$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example - discrete random variable\n",
    "\n",
    "In a game 3 dice are rolled. The player bets £1.  They get back £1 if they roll a single 5, £2 if 2 fives come up, and £3 if 3 fives come up. If no 5s come up they lose their £1 stake.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let us set up a random variable $W$ for the winnings of the player.\n",
    "\n",
    "The sample space is the cartesian product of rolling a die:\n",
    "\n",
    "$S = \\{(x_1,x_2,x_3): x_i = 1,2, \\ldots, 6; i = 1,2,3\\}$\n",
    "\n",
    "Now, we'll define $W$ as the amount the player wins - this can be $-1,1,2,3$ corresponding to 0,1,2, or 3 fives showing:\n",
    "\n",
    "$$\n",
    "V = \n",
    "  \\begin{cases} \n",
    "      \\hfill -1   \\hfill & \\text{if '0 dice lands with 5 spots on the top face'} \\\\\n",
    "      \\hfill 1   \\hfill & \\text{if '1 dice lands with 5 spots on the top face'} \\\\\n",
    "      \\hfill 2   \\hfill & \\text{if '2 dice land with 5 spots on the top face'} \\\\\n",
    "      \\hfill 3   \\hfill & \\text{if '3 dice land with 5 spots on the top face'} \n",
    "  \\end{cases}\n",
    "$$ \n",
    "\n",
    "and our probability mass function will be\n",
    "\n",
    "$$\n",
    "p_V(v) = \n",
    "  \\begin{cases} \n",
    "      \\hfill \\frac{125}{216}   \\hfill & \\text{ for } v = -1 \\\\\n",
    "      \\hfill \\frac{75}{216}   \\hfill & \\text{ for } v = 1 \\\\\n",
    "      \\hfill \\frac{15}{216}   \\hfill & \\text{ for } v = 2 \\\\\n",
    "      \\hfill \\frac{1}{216}   \\hfill & \\text{ for } v = 3 \\\\\n",
    "  \\end{cases}\n",
    "$$\n",
    "\n",
    "note that $p_V(0) > 0.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, suppose the player plays the game $n >> 1$ times.\n",
    "\n",
    "They win $v_1$ pounds the first time, $v_2$ the second time, $\\ldots$ ,$v_n$ pounds the $n^{th}$ time. The average amount one would then be a standard average\n",
    "\n",
    "$$\n",
    "\\bar{v} = \\frac{1}{n}\\sum_{i=1}^{n} v_i\n",
    "$$\n",
    "\n",
    "Now each of the $v_i$ can only be $-1,1,2,3$. \n",
    "\n",
    "Lets reorganise our results and say that $k_{-1}$ times they got $v_i = -1$, $k_1$ times $v_i = 1$, $k_2$ times $v_i = 2$ and $k_3$ times $v_i = 3$. Where $k_{-1} + k_1 + k_2 + k_3$ will be equal to $n$ because we are just placing our $n$ values into these boxes, then\n",
    "\n",
    "$$\n",
    "\\bar{v} = \\frac{1}{n}\\sum_{i=1}^{n} v_i = (-1) \\frac{k_{-1}}{n} + (1) \\frac{k_{1}}{n} + (2) \\frac{k_{2}}{n} + (3) \\frac{k_{3}}{n}  \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\n",
    "\\bar{v} = \\frac{1}{n}\\sum_{i=1}^{n} v_i = (-1) \\frac{k_{-1}}{n} + (1) \\frac{k_{1}}{n} + (2) \\frac{k_{2}}{n} + (3) \\frac{k_{3}}{n}  \n",
    "$$\n",
    "\n",
    "is our average value - but as $n \\to \\infty$ the ratios $\\frac{k_i}{n}$ tend to our original frequentist definition of probabilities - the number of times something occurs out of the total number of attempts.\n",
    "\n",
    "$$\n",
    "\\frac{k_{-1}}{n} = p_V(-1), \\frac{k_{1}}{n} = p_V(1), \\frac{k_{2}}{n} = p_V(2), \\frac{k_{3}}{n} = p_V(3)\n",
    "$$\n",
    "\n",
    "and finally we get\n",
    "\n",
    "$$\n",
    "\\bar{v} = \\mu_V = \\sum_{i=1}^{n} v_i p_V(i) = \\sum_{v \\in R_V } v p_V(v) \n",
    "$$\n",
    "\n",
    "in this case \n",
    "\n",
    "$$\n",
    "\\text{E} = \\mu_V = \\sum_{v \\in R_V } v p_V(v) = (-1) \\frac{125}{216} + (1) \\frac{75}{216} + (2) \\frac{15}{216} + (3) \\frac{1}{216} = \\frac{-17}{216} = -0.08\n",
    "$$\n",
    "\n",
    "On average the player loses 8p every time they play.\n",
    "\n",
    "Note that the average in _not_ in general a value the $V$ can take on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example - continuous random variable\n",
    "\n",
    "Suppose you meet that friend of yours that is always late. You, of course, arrive on time ($T=0$), your friend shows up at a random time $T > 0$ with probability density function\n",
    "\n",
    "$$\n",
    "f_T(t) = \\frac{2}{15} - \\frac{2t}{225}, 0 < t < 15\n",
    "$$\n",
    "\n",
    "We'll ignore other times, where $f_T(t) = 0$\n",
    "\n",
    "We could break this interval up into a large number, $n$, of small pieces with length $\\Delta t = 15/n$ and let $t_1, t_2, t_3, \\ldots , t_n$ be the midpoints of these small intervals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The probability of your friend arriving between at time $t_i$ is approximately $P( t_i - \\Delta t/2 < T < t_i + \\Delta t/2 ) \\approx f_T(t_i) \\Delta t$.\n",
    "\n",
    "We'd expect our average waiting time to be about $\\sum_{i=1}^n t_i f_T(t_i) \\Delta t$ - the sum of the product of length of wait, $t_i$, times the probability of waiting that long, $f_T(t_i) \\Delta t$. The same as for the discrete random variable case.\n",
    "\n",
    "If we now take $n$ larger and large towards infinity, we get\n",
    "\n",
    "$$\n",
    "\\int_{0}^{15} tf_T(t) \\text{d}t = \\int_{0}^{15} t\\Big(\\frac{2}{15} - \\frac{2t}{225}\\Big) \\text{d}t = 5 \\text{ (minutes)}\n",
    "$$\n",
    "This is the length of time you expect to wait for your friend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Expectation of a function of a random variable\n",
    "\n",
    "**Definition**\n",
    "\n",
    "<div style=\"background-color:Gold; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left: 8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;\">\n",
    "\n",
    "Let $g(X)$ be any function of a discrete random variable $X$. \n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "\\text{E}[g(X)] = \\sum_{x \\in X}g(x) \\cdot p(x)\n",
    "$$\n",
    "\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "<div style=\"background-color:Gold; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left: 8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;\">\n",
    "\n",
    "Let $h(Z)$ be any function of  the continuous random variable $Z$\n",
    "\n",
    "$$\n",
    "\\text{E}[h(Z)] = \\int_{-\\infty}^{\\infty} h(z)\\cdot f(z) \\mathrm{d}z\n",
    "$$\n",
    "</div>\n",
    "\n",
    "these can be understood in the same way as $\\text{E}[X]$, it is the value of $g(X)$ times the probability of getting that value $X=x$, and hence $g(x)$. \n",
    "\n",
    "The derivation using repetitions of experiments can be repeated, but replacing $v_i$ with $g(v_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example**\n",
    "\n",
    "Find $\\text{E}[X^2]$ for the continuous random variable $X$ with probability density function \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f_X(x) & = \\frac{3}{4}x(2-x): 0 \\leq x \\leq 2 \\\\ \n",
    "     & = 0 \\text{   otherwise}\n",
    "\\end{align}     \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "taking our general formula\n",
    "\n",
    "$$\n",
    "\\text{E}[h(Z)] = \\int_{-\\infty}^{\\infty} h(z)\\cdot f(z) \\mathrm{d}z\n",
    "$$\n",
    "\n",
    "we fill in for our particular $f_X(x)$\n",
    "\n",
    "$$\n",
    "\\text{E}[X^2] = \\int_0^2 x^2 \\cdot \\frac{3}{4} x(2-x) \\mathrm{d}x = \\frac{6}{5}\n",
    "$$\n",
    "\n",
    "where we ignored the parts of the improper integral $\\int_{-\\infty}^{\\infty} x^2 \\cdot f(x) \\mathrm{d}x$ where $f(x)$ is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\text{E}[g(X)]$ can be interpreted as the 'average' (mean) value of the $g(X)$. \n",
    "\n",
    "**It is a number not a function.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example\n",
    "\n",
    "$\\text{E}[a] = a$, where $a$ is a constant for any random variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "this is a special case of \n",
    "$$\n",
    "\\text{E}[g(X)] = \\sum_{x \\in X}g(x) \\cdot p(x)\n",
    "$$\n",
    "with $g(X) = a$. So\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{E}[a] & = \\sum_{x \\in R_X} g(x) \\cdot p_X(x) \\\\\n",
    "            & = \\sum_{x \\in R_X} a \\cdot p_X(x) \\\\\n",
    "            & = a \\sum_{x \\in R_X}  p_X(x) \\\\\n",
    "            & = a\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "because the sum of all the $p_X(x)$ must be 1 for a valid probability mass function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary of part 1\n",
    "\n",
    "we have given the definitions of\n",
    "- expectation of random variables\n",
    "- expectation of functions of a random variable"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
