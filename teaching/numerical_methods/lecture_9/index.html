
<!DOCTYPE html>
<html>
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="chrome=1" />

  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

  <title>Questions and applications</title>

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.11.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.11.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <link rel="stylesheet" type="text/css" href="https://jsxgraph.uni-bayreuth.de/distrib/jsxgraph.css" />
  <script type="text/javascript" src="https://jsxgraph.uni-bayreuth.de/distrib/jsxgraphcore.js"></script>  
  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

  <!-- General and theme style sheets -->
  <link rel="stylesheet" href="../../../revealjs/css/reveal.css">
  <link rel="stylesheet" href="../../../revealjs/css/theme/beige.css" id="theme">

  <!-- If the query includes 'print-pdf', include the PDF print sheet -->
  <script>
    if( window.location.search.match( /print-pdf/gi ) ) {
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = '../../../revealjs/css/print/pdf.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    }

  </script>

  <!--[if lt IE 9]>
  <script src="../../../revealjs//lib/js/html5shiv.js"></script>
<![endif]-->

<!-- Loading the mathjax macro -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  tex2jax: {
  inlineMath: [ ['$','$'], ["\\(","\\)"] ],
  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
  processEscapes: true,
  processEnvironments: true
},
// Center justify equations in code and markdown cells. Elsewhere
// we use CSS to left justify single line equations in code cells.
displayAlign: 'center',
"HTML-CSS": {
styles: {'.MathJax_Display': {"margin": 0}},
linebreaks: { automatic: true }
}
});
</script>
<!-- End of mathjax configuration -->

<!-- Get Font-awesome from cdn -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.1.0/css/font-awesome.css">

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="../custom.css">

</head>
<body>

  <div class="reveal">
    <div class="slides">

      <section data-background-image="https://upload.wikimedia.org/wikipedia/commons/d/db/LIGO_measurement_of_gravitational_waves.svg">
        <h2 style="color:black;" id="Numerical Methods Week 9">Numerical Methods Week 9<a class="anchor-link" href="#Numerical Methods Week 9">&#182;</a></h2>
        <h1 style="color:black;" id="Questions">Questions<a class="anchor-link" href="#Questions">&#182;</a></h1>
        <div style="background-color:Lavender; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left:
        8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;">	
        <p>Learning outcomes:</p>
      </div>
      <br>
      <div style="background-color:Gold; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left:
      8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;">
      <li> Practice using finite differences to solve end point differential equations.</li>
    </div>
    <br>
    <div style="background-color:Lavender; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left:
    8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;">

    <h3>Matt Watkins mwatkins@lincoln.ac.uk<a class="anchor-link" href="#Matt Watkins">&#182;</a></h3>
  </div>
</section>

<section>
  <h2>differential equations</h2>
  <p>Some differential equations can be solved numerically as follows (more details next term).</p>
  <p>We can approximate a function $y = f(x)$ on a grid of $n$ points that are spaced by $\Delta x$.</p>
  <p>We can approximate derivatives of $y$ by finite differences
   $$
   \frac{\text{d}^2 y}{\text{d} x^2} \Big|_i
   = \frac{(y_{i+1}-y_{i})/\Delta x - (y_{i}-y_{i-1})/\Delta x}{\Delta x} = \frac{y_{i+1} - 2y_i + y_{i-1}}{\Delta x^2}
   $$
 </p>
 <p>In matrix form we can write this as
   $$
   \frac{1}{\Delta x^2}
   \begin{pmatrix}
   -2 &  0 &  0 &  0 & 0 & 0 & 0 & 0 \\
   1 & -2 &  1 &  0 & 0 & 0 & 0 & 0 \\
   0 & \ddots & \ddots & \ddots & 0 & 0 & 0 & 0\\
   0 & 0 & 1 & -2 &  1 &  0 & 0 & 0  \\
   0 & 0 & 0 & \ddots & \ddots & \ddots & 0 & 0\\
   0 & 0 & 0 & 0 & 0 & 1 & -2 &  1   \\
   0  &  0 &  0 &  0 & 0 & 0 & 0 & -2 \\
   \end{pmatrix}
   \begin{pmatrix}
   y_0\\
   y_1\\
   \vdots\\
   y_i\\
   \vdots\\
   y_{n-2}\\
   y_{n-1}\\
   \end{pmatrix}
   $$
 </p>
</section>


<section>
  <div class="inner_cell">
    <h2 id="Finite differences">Finite differences<a class="anchor-link" href="#Finite differences">&#182;</a></h2>
    <p>We can cut our independent variable into a set of equally spaced points</p>
    <form>
     <input type="button" value="Add point" onclick="addPoint()">
   </form>
    <div id="box1" class="jxgbox" style="width:800px; height:350px;"></div>
    <p>The gap between the points, $\Delta x$, is given by the range of the interval divided by the number of points -1.</p>
    <script>
     var board = JXG.JSXGraph.initBoard('box1', {boundingbox: [-1, 3, 4, -3], axis: true});
     var N = 10;
     var p = [];
     function addPoint() {
      N = N + 1      
      p[i] = board.create('point',[
         function(x){ return function(){ return x / N *last.X(); };}(i), 0
       ], {name:'x' + i,style:4});
      board.update();
      i = i + 1
    }

     p[0] = board.create('point', [0,0], {name:'x_0',style:4, size:4});
     last = board.create('point', [3,0], {name:'x_{N-1}',style:4, size:4});

      board.on('move', function(){
              last.moveTo([last.X(), 0]);
      });
     var i;
     for (i=1;i<N;i++) {
       p[i] = board.create('point',[
         function(x){ return function(){ return x / N *last.X(); };}(i), 0
       ], {name:'x' + i,style:4});
      }
      l0 = board.create('point', [function(){ return p[0].X(); }, 0.5], {name:'',style:1, size:0});
      l1 = board.create('point', [function(){ return p[1].X(); }, 0.5], {name:'',style:1, size:0});
      var li = board.create('line',[l0,l1], {straightFirst:false, straightLast:false, firstArrow:true, lastArrow:true, strokeWidth:2, dash:2, name:"dx"});
        board.create('text',[function(){ return p[1].X()/2; }, 0.75,"dx"], {anchor: p[1]});

   </script>
 </div>
</section>

<section>
  <h2>differential equations</h2>
  <p>Some differential equations can be solved numerically as follows (more details next term).</p>
  <p>We can approximate a function $y(x) = f(x)$ on a grid of $n$ points that are spaced by $\Delta x$.</p>
  <p>We can approximate derivatives of $y(x_i)$ by finite differences   
   $$ 
    \frac{d y(x_i)}{d x} \approx \frac{(y_{i+\Delta x/2}-y_{i - \Delta x/2})}{\Delta x}
   $$
   and then using this approximation again we get:
   $$
   \frac{\text{d}^2 y(x_i)}{\text{d} x^2} \approx
     \left( \frac{d y(x_i + \Delta x/2)}{d x} - \frac{d y(x_i - \Delta x/2)}{d x}\right) / \Delta x
   = \frac{(y_{i+1}-y_{i})/\Delta x - (y_{i}-y_{i-1})/\Delta x}{\Delta x} = \frac{y_{i+1} - 2y_i + y_{i-1}}{\Delta x^2}
   $$

 </p>
 <p>This is known as central differences - you can also work with forward or backward differences to get different approximations.
</p>
</section>
<section>

 <p>In matrix form we can write this as
   $$
   \frac{1}{\Delta x^2}
   \begin{pmatrix}
   -2 &  0 &  0 &  0 & 0 & 0 & 0 & 0 \\
   1 & -2 &  1 &  0 & 0 & 0 & 0 & 0 \\
   0 & \ddots & \ddots & \ddots & 0 & 0 & 0 & 0\\
   0 & 0 & 1 & -2 &  1 &  0 & 0 & 0  \\
   0 & 0 & 0 & \ddots & \ddots & \ddots & 0 & 0\\
   0 & 0 & 0 & 0 & 0 & 1 & -2 &  1   \\
   0  &  0 &  0 &  0 & 0 & 0 & 0 & -2 \\
   \end{pmatrix}
   \begin{pmatrix}
   y_0\\
   y_1\\
   \vdots\\
   y_i\\
   \vdots\\
   y_{n-2}\\
   y_{n-1}\\
   \end{pmatrix}
   $$
 </p>
 <p>If we multiply out the 2nd row we get
$$
\frac{1}{\Delta x^2}(y_0 - 2y_1 + y_2) \approx \frac{d^2y(x_1)}{dx^2}
$$
and the 3rd row gives
$$
\frac{1}{\Delta x^2}(y_1 - 2y_2 + y_3) \approx \frac{d^2y(x_2)}{dx^2}
$$
...
 </p>
</section>
<section>
  <h2>Differential equation</h2>
  <p>
   We can write
   $$
   \frac{\text{d}^2 y(x) }{\text{d} x^2} = g(x)
   $$
   where $g(x)$ contains everything that is not a function of $y$ as
   $$
   \begin{pmatrix}
   -2 &  0 &  0 &  0 & 0 & 0 & 0 & 0 \\
   1 & -2 &  1 &  0 & 0 & 0 & 0 & 0 \\
   0 & \ddots & \ddots & \ddots & 0 & 0 & 0 & 0\\
   0 & 0 & 1 & -2 &  1 &  0 & 0 & 0  \\
   0 & 0 & 0 & \ddots & \ddots & \ddots & 0 & 0\\
   0 & 0 & 0 & 0 & 0 & 1 & -2 &  1   \\
   0  &  0 &  0 &  0 & 0 & 0 & 0 & -2 \\
   \end{pmatrix}
   \begin{pmatrix}
   y_0\\
   y_1\\
   \vdots\\
   y_i\\
   \vdots\\
   y_{n-2}\\
   y_{n-1}\\
   \end{pmatrix}
   =
   \begin{pmatrix}
   -2 y_L\\
   g_1 \Delta x^2\\
   \vdots\\
   g_i \Delta x^2\\
   \vdots\\
   g_{n-2} \Delta x^2\\
   -2 y_R\\
   \end{pmatrix}
   $$
   where $y_L$ and $y_R$ are the values of $y$ at the left and right boundaries.
 </p>
 <p>This is a set of linear equations that can be solved using Gauss Elimination, or other methods such as LU decomposition (see later).</p>
</section>

<section>
  <p>
   $$
   \begin{pmatrix}
   -2 &  0 &  0 &  0 & 0 & 0 & 0 & 0 \\
   1 & -2 &  1 &  0 & 0 & 0 & 0 & 0 \\
   0 & \ddots & \ddots & \ddots & 0 & 0 & 0 & 0\\
   0 & 0 & 1 & -2 &  1 &  0 & 0 & 0  \\
   0 & 0 & 0 & \ddots & \ddots & \ddots & 0 & 0\\
   0 & 0 & 0 & 0 & 0 & 1 & -2 &  1   \\
   0  &  0 &  0 &  0 & 0 & 0 & 0 & -2 \\
   \end{pmatrix}
   \begin{pmatrix}
   y_0\\
   y_1\\
   \vdots\\
   y_i\\
   \vdots\\
   y_{n-2}\\
   y_{n-1}\\
   \end{pmatrix}
   =
   \begin{pmatrix}
   -2 y_L\\
   g_1 \Delta x^2\\
   \vdots\\
   g_i \Delta x^2\\
   \vdots\\
   g_{n-2} \Delta x^2\\
   -2 y_R\\
   \end{pmatrix}
   $$
   Multiplying out the 2nd row (and dividing by $\Delta x^2$) we get
   $$
   \frac{1}{\Delta x^2}(y_0 - 2y_1 + y_2) \approx \frac{d^2y(x_1)}{dx^2} = g(x_1)
   $$
   and for the third row
   $$
   \frac{1}{\Delta x^2}(y_1 - 2y_2 + y_3) \approx \frac{d^2y(x_2)}{dx^2} = g(x_2)
   $$
   the same for other rows.</p>
   <p>
   Notice I multiplied through by $\Delta x^2$ because this will be small and can cause numerical problems if you divide numbers by it.
  </p>

</section>

<section>
  <h2>
    Boundary conditions
  </h2>
  <p>
    Note that the first and last rows are different. They are completely decoupled from the others and just read
    $$
    -2 y_0 = -2 y_L
    $$
    and
    $$
    -2 y_{N-1} = -2 y_R
    $$
    i.e. that the boundary conditions are satisfied at the edges of the range we are solving over.
  </p>
  <p> The boundary values are fixed, but they effect the other points because they appear in other rows
  $$
   \frac{1}{\Delta x^2}(y_L - 2y_1 + y_2) \approx \frac{d^2y(x_1)}{dx^2} = g(x_1)
   $$ 
 </p>

</section>

<section>
  <div style="background-color:Lavender; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left:
  8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;">
  <h2>Example: $\frac{\text{d}^2 y}{\text{d} x^2} = x$</h2>
  <p>Find a solution for $y$ in the interval [0,1] when:
   <br> $g(x) = x, y_L = 0.2, y_R=1.5$ with $n=10, 100, 500$</p>
 </div>
 <p></p>
 <div style="background-color:Gold; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left:
 8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;">
 If we discretize into $n$ points we get get our points $x_i = 0 + \frac{i (1-0)}{(n-1)}$.<br>
 We can write our equations at each point as:
 $$
 \begin{pmatrix}
 -2 &  0 &  0 &  0 & 0 & 0 & 0 & 0 \\
 1 & -2 &  1 &  0 & 0 & 0 & 0 & 0 \\
 0 & \ddots & \ddots & \ddots & 0 & 0 & 0 & 0\\
 0 & 0 & 1 & -2 &  1 &  0 & 0 & 0  \\
 0 & 0 & 0 & \ddots & \ddots & \ddots & 0 & 0\\
 0 & 0 & 0 & 0 & 0 & 1 & -2 &  1   \\
 0  &  0 &  0 &  0 & 0 & 0 & 0 & -2 \\
 \end{pmatrix}
 \begin{pmatrix}
 y_0\\
 y_1\\
 \vdots\\
 y_i\\
 \vdots\\
 y_{n-2}\\
 y_{n-1}\\
 \end{pmatrix}
 =
 \begin{pmatrix}
 -2 \times 0.2\\
 x_1 \Delta x^2\\
 \vdots\\
 x_i \Delta x^2\\
 \vdots\\
 x_{n-2} \Delta x^2\\
 -2 \times 1.5\\
 \end{pmatrix}
 $$
</div>
</section>

<section>
  <div style="background-color:Lavender; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left:
  8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;">
  <h2>Example $\frac{\text{d}^2 y}{\text{d} x^2} = g(x)$</h2>
  
  <p> Solve when $g(x_{n/2}) = 1/\Delta x$, all other $g_i = 0$ and $y_L = 0, y_R=0$ in the interval $[-5,5]$</p>
</div>
<p></p>
<div style="background-color:Gold; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left:
8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;">
If we discretize into $n$ points we get get our points $x_i = -5 + \frac{i (5--5)}{(n-1)}$.<br>
We can write our equations at each point as:
$$
\begin{pmatrix}
-2 &  0 &  0 &  0 & 0 & 0 & 0 & 0 \\
1 & -2 &  1 &  0 & 0 & 0 & 0 & 0 \\
0 & \ddots & \ddots & \ddots & 0 & 0 & 0 & 0\\
0 & 0 & 1 & -2 &  1 &  0 & 0 & 0  \\
0 & 0 & 0 & \ddots & \ddots & \ddots & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 1 & -2 &  1   \\
0  &  0 &  0 &  0 & 0 & 0 & 0 & -2 \\
\end{pmatrix}
\begin{pmatrix}
y_0\\
y_1\\
\vdots\\
y_{n/2}\\
\vdots\\
y_{n-2}\\
y_{n-1}\\
\end{pmatrix}
=
\begin{pmatrix}
-2 \times 0\\
0 \times  \Delta x^2\\
\vdots\\
\frac{1}{\Delta x}  \Delta x^2\\
\vdots\\
0 \times \Delta x^2\\
-2 \times 0\\
\end{pmatrix}
$$
</div>
</section>

<section>
  <div style="background-color:Lavender; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left:
  8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;">
  <h2>Example $\frac{\text{d}^2 y}{\text{d} x^2} + ky = C$</h2>
  
  <p> Solve $\frac{\text{d}^2 y}{\text{d} x^2} + ky = g(x)$ when $g(x) = C$, $y_L = 5, y_R=0$ in the interval $[-3,3]$</p>
</div>
<p></p>
<div style="background-color:Gold; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left:
8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;">
To get our linear equation we must have $\textbf{D(x)} y(x) = g(x)$, in this case the LHS must approximate $ (\frac{\text{d}^2 }{\text{d} x^2} + k) y$
$$
\begin{pmatrix}
-2 &  0 &  0 &  0 & 0 & 0 & 0 & 0 \\
1 & -2 + k \Delta x^2&  1 &  0 & 0 & 0 & 0 & 0 \\
0 & \ddots & \ddots & \ddots & 0 & 0 & 0 & 0\\
0 & 0 & 1 & -2 + k \Delta x^2&  1 &  0 & 0 & 0  \\
0 & 0 & 0 & \ddots & \ddots & \ddots & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 1 & -2 + k \Delta x^2 &  1   \\
0  &  0 &  0 &  0 & 0 & 0 & 0 & -2 \\
\end{pmatrix}
\begin{pmatrix}
y_0\\
y_1\\
\vdots\\
y_i\\
\vdots\\
y_{n-2}\\
y_{n-1}\\
\end{pmatrix}
$$
</div>
</section>

<section>
  <div style="background-color:Gold; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left:
  8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;">
  <h3>Task Solve the question in the Week 9 online test.</h3>
  <h3>Note, you will need to think how to include the first derivative of y into the LHS too.</h3>
</div>
</section>

   <section>
      <h2 id="LU decomposition">LU decomposition<a class="anchor-link" href="#LU decomposition">&#182;</a></h2>
      <p>Again we want to solve $\textbf{Ax - b} = 0$</p>
      <p class='fragment'> Suppose we can rewrite this as 
  \[
  \left( \begin{array}{ccc}
  u_{00} & u_{01} & u_{02} \\ 
  0 & u_{11} & u_{12} \\ 
  0 & 0 & u_{22} \\ 
  \end{array} \right)
  \left( \begin{array}{c}
  x_{0} \\ 
  x_{1} \\ 
  x_{2} \\ 
  \end{array} \right) - 
  \left( \begin{array}{c}
  d_{0} \\ 
  d_{1} \\ 
  d_{2} \\ 
  \end{array} \right)
        = 0
  \]
  which looks similar to Gauss elmination. In matrix notation $$\textbf{Ux - d = 0}$$.
      </p>
      <p class='fragment'>Now, assume there is a lower diagonal matrix $\textbf{L}$ with '1's on the diagonal
  \[
  \left( \begin{array}{ccc}
  1 & 0 & 0 \\ 
  l_{10} & 1 & 0 \\ 
  l_{20} & l_{21} & 1 \\ 
  \end{array} \right)
  \]
      </p>
      <p class='fragment'>that has the property that, premultiplying by $\textbf{L}$ we get
  $$
  \textbf{LUx} - \textbf{Ld} = \textbf{Ax} - \textbf{b}  
  $$
      </p>
    </section>
    
    <section>
      <h2 id="LU decomposition">LU decomposition<a class="anchor-link" href="#LU decomposition">&#182;</a></h2>
      <p> To ensure that
  $$
  \textbf{LUx} - \textbf{Ld} = \textbf{Ax} - \textbf{b}  
  $$
  we require that
      </p>
      <p class='fragment'>
  $$
  \textbf{LU = A}
  $$
  and
  $$
  \textbf{Ld = b}
  $$
      </p>
    </section>

    <section>
      <section>
  <h2 id="Gaussian Elimination">Gaussian Elimination<a class="anchor-link" href="#Gaussian Elimination">&#182;</a></h2>    
  <h3 id="Triangularization">Triangularization<a class="anchor-link" href="#Triangularization">&#182;</a></h3>      
  <p>When we do the Gauss elimination method, we actually find all the elements of $\textbf{L}$, we just need to store them. <br> It is the inverse of the matrix we would need to multiply $\textbf{b}$ by to get the correct RHS in the Gauss elmination method. </p>
  <p>Let us take an initial augmented matrix, and record the values that we would scale the $\textbf{b}$ matrix by if it were there: 
    \[ \left( \begin{array}{cccc}
    a_{00} & a_{01} & a_{02} & a_{03}\\ 
    a_{10} & a_{11} & a_{12} & a_{13}\\ 
    a_{20} & a_{21} & a_{22} & a_{23}\\ 
    a_{30} & a_{31} & a_{32} & a_{33}\\ 
    \end{array} \right) \]
  </p>
  <p class=fragment>
    pivoting around row 0, we remove all entries below the diagonal entry in column 0, doing this we scaled the $\textbf{b}$ matrix by the ratios shown on the right
    \[ \left( \begin{array}{cccc}
    a_{00} & a_{01} & a_{02} & a_{03}\\ 
    0      & a'_{11} & a'_{12} & a'_{13}\\ 
    0      & a'_{21} & a'_{22} & a'_{23}\\ 
    0      & a'_{31} & a'_{32} & a'_{33}\\ 
    \end{array} \right)
    \qquad
    \left( \begin{array}{cccc}
    1 & 0 & 0 & 0\\ 
    \frac{a_{10}}{a_{00}} &  &  &  & \\ 
    \frac{a_{20}}{a_{00}} &  &  &  & \\ 
    \frac{a_{30}}{a_{00}} &  &  &  & \\ 
    \end{array} \right) \]
  </p>
      </section>
      <section>
  <p>
    Matrix after pivoting around row 0
    \[ \left( \begin{array}{cccc}
    a_{00} & a_{01} & a_{02} & a_{03}\\ 
    0      & a'_{11} & a'_{12} & a'_{13}\\ 
    0      & a'_{21} & a'_{22} & a'_{23}\\ 
    0      & a'_{31} & a'_{32} & a'_{33}\\ 
    \end{array} \right)
    \qquad
    \left( \begin{array}{cccc}
    1 & 0 & 0 & 0\\ 
    \frac{a_{10}}{a_{00}} &  &  &  & \\ 
    \frac{a_{20}}{a_{00}} &  &  &  & \\ 
    \frac{a_{30}}{a_{00}} &  &  &  & \\ 
    \end{array} \right) \]
  </p><p class=fragment>
    Then pivoting around row 1 we remove elements below the diagonal in column 1, and subtract multiples of the 2nd row of $\textbf{b}$ as shown in the right hand matrix
    \[ \left( \begin{array}{cccc}
    a_{00} & a_{01} & a_{02} & a_{03}\\ 
    0      & a'_{11} & a'_{12} & a'_{13}\\ 
    0      & 0       & a''_{22} & a''_{23}\\ 
    0      & 0       & a''_{32} & a''_{33}\\ 
    \end{array} \right)
    \qquad
    \left( \begin{array}{cccc}
    1 &  &  & \\ 
    \frac{a_{10}}{a_{00}} & 1  &  &  & \\ 
    \frac{a_{20}}{a_{00}} & \frac{a'_{21}}{a'_{10}} &  &  & \\ 
    \frac{a_{30}}{a_{00}} & \frac{a'_{31}}{a'_{10}} &  &  & \\ 
    \end{array} \right) \]
  </p><p class=fragment>    
    pivoting around row 2
    \[ \left( \begin{array}{cccc}
    a_{00} & a_{01} & a_{02} & a_{03}\\ 
    0      & a'_{11} & a'_{12} & a'_{13}\\ 
    0      & 0       & a''_{22} & a''_{23}\\ 
    0      & 0       & 0        & a'''_{33}\\ 
    \end{array} \right)
    \qquad
    \left( \begin{array}{cccc}
    1 &  &  & \\ 
    \frac{a_{10}}{a_{00}} & 1  &  &  & \\ 
    \frac{a_{20}}{a_{00}} & \frac{a'_{21}}{a'_{11}} &  1 &  & \\ 
    \frac{a_{30}}{a_{00}} & \frac{a'_{31}}{a'_{11}} & \frac{a''_{32}}{a''_{22}} &  & \\ 
    \end{array} \right) \]
  </p>
      </section>
      <section>
        <p>   
    we had got to
    \[ \left( \begin{array}{cccc}
    a_{00} & a_{01} & a_{02} & a_{03}\\ 
    0      & a'_{11} & a'_{12} & a'_{13}\\ 
    0      & 0       & a''_{22} & a''_{23}\\ 
    0      & 0       & 0        & a'''_{33}\\ 
    \end{array} \right)
    \qquad
    \left( \begin{array}{cccc}
    1 &  &  & \\ 
    \frac{a_{10}}{a_{00}} & 1  &  &  & \\ 
    \frac{a_{20}}{a_{00}} & \frac{a'_{21}}{a'_{11}} &  1 &  & \\ 
    \frac{a_{30}}{a_{00}} & \frac{a'_{31}}{a'_{11}} & \frac{a''_{32}}{a''_{22}} &  & \\ 
    \end{array} \right) \]
  </p>
      <p class='fragment'>    
    if we fill in the rest of the matrix on the right we have
    \[ \left( \begin{array}{cccc}
    a_{00} & a_{01} & a_{02} & a_{03}\\ 
    0      & a'_{11} & a'_{12} & a'_{13}\\ 
    0      & 0       & a''_{22} & a''_{23}\\ 
    0      & 0       & 0        & a'''_{33}\\ 
    \end{array} \right)
    \qquad
    \left( \begin{array}{cccc}
    1 & 0 & 0 & 0\\ 
    \frac{a_{10}}{a_{00}} & 1  & 0 & 0 & \\ 
    \frac{a_{20}}{a_{00}} & \frac{a'_{21}}{a'_{11}} &  1 & 0 & \\ 
    \frac{a_{30}}{a_{00}} & \frac{a'_{31}}{a'_{11}} & \frac{a''_{32}}{a''_{22}} & 1 & \\ 
    \end{array} \right) \]
  </p>
      </section>
      <section>
  <p'>
    We can show for a real system that this new matrix is $\textbf{L}$
    \[ \left( \begin{array}{cccc}
    1 & 0 & 0 & 0\\ 
    \frac{a_{10}}{a_{00}} & 1  & 0 & 0 & \\ 
    \frac{a_{20}}{a_{00}} & \frac{a'_{21}}{a'_{11}} &  1 & 0 & \\ 
    \frac{a_{30}}{a_{00}} & \frac{a'_{31}}{a'_{11}} & \frac{a''_{32}}{a''_{22}} & 1 & \\ 
    \end{array} \right)
    \left( \begin{array}{cccc}
    a_{00} & a_{01} & a_{02} & a_{03}\\ 
    0      & a'_{11} & a'_{12} & a'_{13}\\ 
    0      & 0       & a''_{22} & a''_{23}\\ 
    0      & 0       & 0        & a'''_{33}\\ 
    \end{array} \right)
    =
    \left( \begin{array}{cccc}
    a_{00} & a_{01} & a_{02} & a_{03}\\ 
    a_{10} & a_{11} & a_{12} & a_{13}\\ 
    a_{20} & a_{21} & a_{22} & a_{23}\\ 
    a_{30} & a_{31} & a_{32} & a_{33}\\ 
    \end{array} \right) \]
  </p>
  <p'>
  $$
  \textbf{LU = A}
  $$
  and
  $$
  \textbf{Ld = b}
  $$
  </p>
  <pre>
  <code>void gauss_elim(std::ofstream &myout, double (&a)[rows][cols]) {
    double coeff;
    double x[rows];
    for (int i =0; i &lt rows-1; i++) {
        for (int j = i+1; j &lt rows; j++) {
            coeff = a[j][i]/a[i][i];
            for (int k = i; k &lt cols; k++) {
                a[j][k] -= a[i][k]*coeff;
            }
        }
        myout &lt&lt "\n pivoting around row " &lt&lt i &lt&lt "\n\n";
        output_matrix(myout,a);
    }
}
        </code>
  </pre>
      </section>
      <section>
  <p>The entries in $\textbf{L}$ are just what I called `coeff` in the code</p>
  <pre>
  <code>void gauss_elim(std::ofstream &myout, double (&a)[rows][cols]) {
    double coeff;
    double x[rows];
    for (int i =0; i &lt rows-1; i++) {
        for (int j = i+1; j &lt rows; j++) {
            coeff = a[j][i]/a[i][i];
      a[j][i] = coeff;
            for (int k = i+1; k &lt cols; k++) {
                a[j][k] -= a[i][k]*coeff;
            }
        }
    }
}
        </code>
  </pre>
  <p>
    So only very minor changes in the Gauss elimination code are needed. <br>
    Note, I have stored the nondiagonal elements of $\textbf{L}$ in what would be the zero elements of the row echelon matrix.
  </p>
      </section>

    </section>
    
    <section>
      <h2 id="LU decomposition">LU decomposition<a class="anchor-link" href="#LU decomposition">&#182;</a></h2>
      <p>The major advantage of LU decompostion is we calculate $\textbf{L}$ and $\textbf{U}$ once, then we can easily find $\textbf{x}$ for any $\textbf{b}$</p>
      <p>Having $\textbf{L}$ we can solve $\textbf{Ld} = \textbf{b}$ for $\textbf{d}$ by forward substitution
  \[ \left( \begin{array}{cccc}
  1 & 0 & 0 & 0\\ 
  \frac{a_{10}}{a_{00}} & 1  & 0 & 0 & \\ 
  \frac{a_{20}}{a_{00}} & \frac{a'_{21}}{a'_{11}} &  1 & 0 & \\ 
  \frac{a_{30}}{a_{00}} & \frac{a'_{31}}{a'_{11}} & \frac{a''_{32}}{a''_{22}} & 1 & \\ 
  \end{array} \right)
  \left( \begin{array}{c}
  d_0 \\ d_1 \\ d_2 \\ d_3 \\
  \end{array} \right)
  =
  \left( \begin{array}{c}
  b_0 \\ b_1 \\ b_2 \\ b_3 \\
  \end{array} \right)\]
  i.e. multiplying out the equations starting from the top row.
      </p>
      <p> Then, having constructed $\textbf{d}$ for the given $\textbf{b}$ we continue exactly like in Gauss Elimination using back substitution to find $\textbf{x}$
  \[\left( \begin{array}{cccc}
  a_{00} & a_{01} & a_{02} & a_{03}\\ 
  0      & a'_{11} & a'_{12} & a'_{13}\\ 
  0      & 0       & a''_{22} & a''_{23}\\ 
  0      & 0       & 0        & a'''_{33}\\ 
  \end{array} \right)
  \left( \begin{array}{c}
  x_0 \\ x_1 \\ x_2 \\ x_3 \\
  \end{array} \right)
  =
  \left( \begin{array}{c}
  d_0 \\ d_1 \\ d_2 \\ d_3 \\
  \end{array} \right)\]

      </p>
    </section>
    
    <section>
      <h2 id="LU decomposition">LU decomposition<a class="anchor-link" href="#LU decomposition">&#182;</a></h2>
      <p> We can use LU decomposition to find the inverse of a matrix, by setting $b$ to the columns of the identity matrix, $I$.
      </p>
      <p>For example we get the first column of $\textbf{A}^{-1}$ by using $\textbf{b}^T = (1,0,0,0)$
  \[ \left( \begin{array}{cccc}
  1 & 0 & 0 & 0\\ 
  \frac{a_{10}}{a_{00}} & 1  & 0 & 0 & \\ 
  \frac{a_{20}}{a_{00}} & \frac{a'_{21}}{a'_{11}} &  1 & 0 & \\ 
  \frac{a_{30}}{a_{00}} & \frac{a'_{31}}{a'_{11}} & \frac{a''_{32}}{a''_{22}} & 1 & \\ 
  \end{array} \right)
  \left( \begin{array}{c}
  d_0 \\ d_1 \\ d_2 \\ d_3 \\
  \end{array} \right)
  =
  \left( \begin{array}{c}
  1 \\ 0 \\ 0 \\ 0 \\
  \end{array} \right)\]
  i.e. multiplying out the equations starting from the top row.
      </p>
      <p> Then, having constructed $\textbf{d}$ for the given $\textbf{b}$ we continue exactly like in Gauss Elimination using back substitution to find $\textbf{x}$
  \[\left( \begin{array}{cccc}
  a_{00} & a_{01} & a_{02} & a_{03}\\ 
  0      & a'_{11} & a'_{12} & a'_{13}\\ 
  0      & 0       & a''_{22} & a''_{23}\\ 
  0      & 0       & 0        & a'''_{33}\\ 
  \end{array} \right)
  \left( \begin{array}{c}
  A^{-1}_{00} \\ A^{-1}_{10} \\ A^{-1}_{20} \\ A^{-1}_{30} \\
  \end{array} \right)
  =
  \left( \begin{array}{c}
  d_0 \\ d_1 \\ d_2 \\ d_3 \\
  \end{array} \right)\]
  The we build the other columns of $\textbf{A}^{-1}$ from the other unit vectors.
      </p>
    </section>

    <section>
      <div style="background-color:Lavender; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left:
                  8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;">
  <p>If you want to understand the LU decomposition clearly, adapt a gauss-elim type code to also perform LU decomposition</p>
  <p> - Find the inverse of the matrix using LU decomposition 
    \[ \left( \begin{array}{cccc}
    2 & 2 & 4 & -2 \\ 
    1 & 3 & 2 & 4 \\ 
    3 & 1 & 3 & 1\\ 
    1 & 3 & 4 & 2 \\ 
    \end{array} \right) \]
    <br>
    Check your solution is correct by comparison to Gauss-Jordan or Eigen / numpy libraries.
    Note you can also get the determinant from LU decomposition.
  </p>      
  
      </div>
    </section>
    
    <section>
      <h2 id="QR decomposition">QR decomposition<a class="anchor-link" href="#QR decomposition">&#182;</a></h2>
      <h4>Why another decomposition???</h4>
      <p>This decomposition is part of the 'QR' algorithm to find the eigenvalues and vectors of a matrix.</p>
      <p>Any real square matrix A may be decomposed as
  $$
  \textbf{A} = \textbf{QR},
  $$
  where
  <li>$\textbf{Q}$ is an orthogonal matrix (its columns are orthogonal unit vectors meaning $\textbf{Q}^t\textbf{Q} = I$)</li>
  <li>$\textbf{R}$ is an upper triangular matrix (also called right triangular matrix).</li></p>
      <p>If $\textbf{A}$ is invertible, then the factorization is unique if we require the diagonal elements of $\textbf{R}$ to be positive.</p>
    </section>

    <section>
      <h2 id="QR decomposition">QR decomposition<a class="anchor-link" href="#QR decomposition">&#182;</a></h2>
      <h4>Gramâ€“Schmidt orthogonalisation.</h4>
      <p>You may remember this from linear algebra - we build an orthogonal basis by sucessively projecting out previous basis vectors</p>
      <p>We can scan across the columns of our matrix $\textbf{A}$ and remove the components of any previous column by subtracting the dot product.</p>
      <p>Take an initial matrix $\textbf{A}$
  $$
  \textbf{A} = 
\begin{pmatrix}
12 & -51 & 4 \\
6 & 167 & -68 \\
-4 & 24 & -41
\end{pmatrix}
  $$
      </p>
      <p>First we'll make an orthogonal matrix $\textbf{U}$, we'll keep the first column.</p>
        $$
  \textbf{U} = 
\begin{pmatrix}
12 & ? & ? \\
 6 & ? & ? \\
-4 & ? & ?
\end{pmatrix}
  $$
      <p>To get the 2nd column orthogonal, we subtract the projection of the second column onto the first column from the 2nd column.</p>
    </section>
    <section>
      <p>To get the 2nd column orthogonal, we subtract the projection of the second column onto the first column from the 2nd column.
  $$
  \textbf{U} = 
  \begin{pmatrix}
  12 & -51 - \text{proj}_{col_1} & ? \\
   6 & 167 - \text{proj}_{col_1} & ? \\
  -4 &  24 - \text{proj}_{col_1} & ?
  \end{pmatrix}
  $$
  where the projection onto the first column is given by
  $$
  \begin{array}
  \text{proj}_{col_1} & = \left \lt \textbf{col}_2 \cdot \frac{\textbf{col}_1}{||col_1||} \right\gt \frac{\textbf{col_1}}{||col_1||} \\
  & = \left \lt (-51, 167, 24)\cdot \begin{pmatrix}12\\6\\4 \end{pmatrix} \right \gt (12, 6, 4) \frac{1 }{(12^2 + 6^2 + 4^2)}  \\
  & = \frac{294}{196} (12 ,6, 4) = (18, 9, -6)
  \end{array}
  $$
  so
  $$
  \textbf{U} = 
  \begin{pmatrix}
  12 & -51 - 18 & ? \\
   6 & 167 - 9 & ? \\
  -4 &  24 - -6 & ?
  \end{pmatrix}
  =
  \begin{pmatrix}
  12 & -69 & ?\\
   6 & 158 & ? \\
  -4 &  30 & ?
  \end{pmatrix}
  $$  
      </p>
    </section>
    <section>
      <p>Two get the 3rd column orthogonal, we subtract the projection of the third column onto the first two columns.
  \begin{align*}
  \textbf{U} & = 
  \begin{pmatrix}
  12 & -69 & 4 - ( \text{proj}_{col_1} + \text{proj}_{col_2}) \\
   6 & 158 & -68 - (\text{proj}_{col_1} + \text{proj}_{col_2}) \\
  -4 &  30 & -41 - (\text{proj}_{col_1} + \text{proj}_{col_2}) \\
  \end{pmatrix}\\
  & =
  \begin{pmatrix}
  12 & -69 & -58/5 \\
   6 & 158 & 6/5 \\
  -4 &  30 & -33 \\
  \end{pmatrix}\\
  \end{align*}
  Now we make each column a unit vector to get the orthogonal matrix $\textbf{Q}$<br>
  $$\textbf{Q} = 
\begin{pmatrix}
\frac{\mathbf u_1}{\|\mathbf u_1\|} &
\frac{\mathbf u_2}{\|\mathbf u_2\|} &
\frac{\mathbf u_3}{\|\mathbf u_3\|}
\end{pmatrix}
=
\begin{pmatrix}
     6/7    &    -69/175   &   -58/175   \\
     3/7    &    158/175   &     6/175   \\
    -2/7    &      6/35    &   -33/35
\end{pmatrix}.
  $$
      </p>
    </section>
    <section>
      <p>Remember, we wanted
  $$
  \textbf{A} = \textbf{QR},
  $$
      </p>
      <p class='fragment'>
  if we premultiply by $\textbf{Q}^T$ we get
  $$
  \textbf{Q}^T\textbf{A} = \textbf{Q}^T\textbf{QR},
  $$
      </p>
      <p class='fragment'>
  but for an orthogonal matrix $\textbf{Q}^T\textbf{Q} = \textbf{I}$ so we have
  $$
  \textbf{Q}^T\textbf{A} = \textbf{R},
  $$
  and we can find $\textbf{R}$ my mulitplying our original matrix $\textbf{A}$ and the (transposed) orthogonal matrix  we just found.
  $$
  \begin{matrix}
  R=Q^{T}A=
  \end{matrix}
  \begin{pmatrix}
  14&21&-14\\
  0&175&-70\\
  0&0&35
  \end{pmatrix}.
  $$
      </p>
    </section>

    <section>
      <h2 id="QR algorithm">QR algorithm<a class="anchor-link" href="#QR algorithm">&#182;</a></h2>
      <p>It can be shown that the sequence
  $$
  \begin{align*}
  \textbf{A}^{0} & = \textbf{A} \\
  \textbf{A}^{k+1} & = \textbf{R}^{k} \textbf{Q}^{k}
  \end{align*}
  $$
  converges to a upper triangular matrix with the eigenvalues of $\textbf{A}$ as its diagonal entries.
      </p>
      <p>
  In the sequence $\textbf{Q}^{k}$ and  $\textbf{R}^{k}$ are formed by the QR decomposition of $\textbf{A}^{k}$
  $$\textbf{A}^{k} = \textbf{Q}^{k} \textbf{R}^{k}$$
      </p>
      <p>
  This algorithm needs modifications to be generally efficient, but gives the general shape of real eigenvalue finding routines.
      </p>
      <p>
  If we have an eigenvalue we can find the corresponding eigenvector using Gauss Elimination.
      </p>
    </section>

    <section>
      <div style="background-color:Lavender; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left:
                  8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;">
  <p>Find the eigenvalues of the following matrices using the QR decomposition code on Bb (or write your own of course):
  <p>
    \begin{pmatrix}
     1 & -1 & -1 & -1\\
    -1 &  2 &  0 &  0\\
    -1 &  0 &  3 &  1\\
    -1 &  0 &  1 &  4
  \end{pmatrix}.
  </p>
  <p>
    \begin{pmatrix}
    1 & 0 & 0 & 1\\
    0 &  1 &  0 & 1/2\\
    0 &  0 &  1 & 1/4\\
    1 &  1/2 &  1/4 &  1
    \end{pmatrix}.
  </p>
  <p>
    Check that your eigenvalues are eigenvalues by running Gauss elimination on the equation $(\textbf{A} - \lambda_i \textbf{I}) \textbf{x} = 0 $.
    The augmented matrix should be of reduced rank, and you can deduce the eigenvectors from the output.
  </p>
  <p>
    Check that an eigenvector you found is an eigenvector with eigenvalue $\lambda_i$ by direct multiplication.
  </p>
  <p>
    Modify the code to output the condition number of a matrix. The condition number is the ratio of the largest to smallest eigenvalue. This controls how numerically stable inversion of the matrix is.
  </p>
    </section>
 
<section>
  <h2 id="Summary and Further Reading">Summary and Further Reading<a class="anchor-link" href="#Summary and Further Reading">&#182;</a></h2>
  <p>You should be reading additional material to provide a solid background to what we do in class</p>
  <p>All the textbooks contain sections on solving linear equations, for instance chapter 2 of <a href="http://www.nrbook.com/a/bookcpdf.php">Numerical Recipes</a>.</p>
</section>

<section>
  <h2 id="Snake">Snake<a class="anchor-link" href="#Snake">&#182;</a></h2>
  <p>Use the arrow keys</p>
  <form><input type="button" onClick="startGame()" value="start game"></form>
  <div id="snakebox" class="jxgbox" style="width:500px; height:500px; overflow:hidden; "></div>
  <script>
    var snakeBoard = JXG.JSXGraph.initBoard('snakebox',{boundingbox: [0, 20, 20, 0],grid:true});
    var snake = {
      points : [[10,11],[10,10]],
      dir : [1,0],
      size: 2,
      newSize: 2,
      speed: 50,
      hitSelf: function(x,y) {
        for (var i=0;i<this.size-1;i++) {
          if (x==this.points[0][i]) if (y==this.points[1][i]) { return true; }
        }
        return false;
      }
    }
    var curve = snakeBoard.create('curve', snake.points , {strokeWidth:20,strokeOpacity:0.5});
    var point = snakeBoard.create('point', [
      Math.round(Math.random()*18)+1,Math.round(Math.random()*18)+1], 
      {strokeColor:'#4CADD4',fillColor:'#4CADD4',strokeWidth:10,name:' '});
    var t = snakeBoard.create('text', [2,1,function() { return snake.size; }], {fontSize:28});

    var setRandomPosition = function()  {
      point.setPositionDirectly(JXG.COORDS_BY_USER,
        [Math.round(Math.random()*18)+1,
        Math.round(Math.random()*18)+1]);
    }
    var keyDown = function (Evt) {
      var code;
      if (!Evt) Evt = window.event;
      if (Evt.which) {
        code = Evt.which;
      } else if (Evt.keyCode) {
        code = Evt.keyCode;
      }
        // 37: left,  38: up,  39: right,  40: down
        if (code==37) { snake.dir = [-1,0]; return false;}
        else if (code==38) { snake.dir = [0,1]; return false;}
        else if (code==39) { snake.dir = [1,0]; return false;}
        else if (code==40) { snake.dir = [0,-1]; return false;}
        return true;
      }
      document.onkeydown = keyDown;

      var crawl = function() {
        if (snake.size>=snake.newSize) {
          snake.points[0].shift();
          snake.points[1].shift();
        }
        var x = snake.points[0][snake.points[0].length-1]+snake.dir[0];
        snake.points[0].push(x);
        var y = snake.points[1][snake.points[1].length-1]+snake.dir[1];
        snake.points[1].push(y);
        snake.size = snake.points[0].length;
        snakeBoard.update();
        if (x>=20 || x<=0 || y>=20 || y<=0 || snake.hitSelf(x,y)) {
          alert('Game over');
        } else {
          if (x==point.X()) if (y==point.Y()) {
            snake.newSize += 5;
            snake.speed -= 10;
            setRandomPosition();
            snakeBoard.update();
          }
          setTimeout(crawl,snake.speed);
        }
      }

      var startGame = function () {
        snake.points[0].splice(0,snake.size,10,11);
        snake.points[1].splice(0,snake.size,10,10);
        snake.dir = [1,0];
        snake.size = 2;
        snake.newSize = 2;
        snake.speed = 200;
        setRandomPosition();
        crawl();
      } 
    </script>
  </section>

</div> <!-- slides -->
</div> <!-- reveal -->

<script>

  require(
  {
      // it makes sense to wait a little bit when you are loading
      // reveal from a cdn in a slow connection environment
      waitSeconds: 15
    },
    [
    "../../../revealjs//lib/js/head.min.js",
    "../../../revealjs//js/reveal.js"
    ],

    function(head, Reveal){

      // Full list of configuration options available here: https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        mouseWheel: false,
        center: false,
        scroll: true,

        // Parallax background image
        //parallaxBackgroundImage: 'https://github.com/mattatlincoln/mattatlincoln.github.io/blob/master/images/CaF2_zoom.jpg?raw=true',
        // Parallax background size
        parallaxBackgroundSize: '2100px 900px', // CSS syntax, e.g. "2100px 900px

        theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
        transition: Reveal.getQueryHash().transition || 'linear', // default/cube/page/concave/zoom/linear/none

        // Optional libraries used to extend on reveal.js
        dependencies: [
        { src: "../../../revealjs//lib/js/classList.js",
        condition: function() { return !document.body.classList; } },
        { src: "../../../revealjs//plugin/notes/notes.js",
        async: true,
        condition: function() { return !!document.body.classList; } }
        ]
      });

      var update = function(event){
        if(MathJax.Hub.getAllJax(Reveal.getCurrentSlide())){
          MathJax.Hub.Rerender(Reveal.getCurrentSlide());
        }
      };

      Reveal.addEventListener('slidechanged', update);

      var update_scroll = function(event){
        $(".reveal").scrollTop(0);
      };

      Reveal.addEventListener('slidechanged', update_scroll);

    }
    );
  </script>

</body>

</html>
