
<!DOCTYPE html>
<html>
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="chrome=1" />

  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

  <title>Numerical Methods - Curve Fitting 2</title>

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.11.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.11.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

  <!-- General and theme style sheets -->
  <link rel="stylesheet" href="../../../revealjs/css/reveal.css">
  <link rel="stylesheet" href="../../../revealjs/css/theme/beige.css" id="theme">

  <!-- If the query includes 'print-pdf', include the PDF print sheet -->
  <script>
    if( window.location.search.match( /print-pdf/gi ) ) {
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = '../../../revealjs/css/print/pdf.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    }

  </script>

  <!--[if lt IE 9]>
  <script src="../../../revealjs//lib/js/html5shiv.js"></script>
<![endif]-->

<!-- Loading the mathjax macro -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  tex2jax: {
  inlineMath: [ ['$','$'], ["\\(","\\)"] ],
  displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
  processEscapes: true,
  processEnvironments: true
},
// Center justify equations in code and markdown cells. Elsewhere
// we use CSS to left justify single line equations in code cells.
displayAlign: 'center',
"HTML-CSS": {
styles: {'.MathJax_Display': {"margin": 0}},
linebreaks: { automatic: true }
}
});
</script>
<!-- End of mathjax configuration -->

<!-- Get Font-awesome from cdn -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.1.0/css/font-awesome.css">

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="../custom.css">

</head>
<body>

  <div class="reveal">
    <div class="slides">

      <section data-background-image="https://upload.wikimedia.org/wikipedia/commons/2/20/Coloured_Voronoi_2D.svg">
        <h2 style="color:white;" id="Numerical Methods Week 3">Numerical Methods Week 3<a class="anchor-link" href="#Numerical Methods Week 3">&#182;</a></h2>
        <h1 style="color:white;" id="Curve Fitting 1">Curve Fitting 1<a class="anchor-link" href="#Curve Fitting 1">&#182;</a></h1>
        <div style="background-color:Lavender; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left:
        8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;">
        <p>We continue with Curve Fitting. This week polynomial and multiple linear regression.</p>
        <p>Reading: Capra and Canale, introduction to part 5 and chapter 17.</p>
      </div>
      <br>
      <div style="background-color:Gold; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left:
      8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;">
      <p>Learning outcomes:</p>
      <li> Extend the work on Linear Regression to polynomial and multiple variables.</li>
      <li> Combine C++ and analytical or other platforms.</li>
      <li> Check your code works correctly, via an external reference.</li>	
    </div>
    <br>
    <div style="background-color:Lavender; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left:
    8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;">

    <h3>Matt Watkins mwatkins@lincoln.ac.uk<a class="anchor-link" href="#Matt Watkins">&#182;</a></h3>
  </div>
</section>

<section>
  <section>
    <div class="inner_cell">    
      <h2 id="Least-squares Regression - summary">Least Squares Regression  - summary<a class="anchor-link" href="#Least Squares Regression - summary">&#182;</a></h2>
      <p> we saw in <a href='https://mattatlincoln.github.io/teaching/numerical_methods/lecture_1/#/'>lecture 1</a> that given our assumption of a straightline
       $$
       y_i = a_0 + a_1 x_i + e_i
       $$
       the error at each point is given by
       $$
       e_i  = y_i - a_0 - a_1 x_i
       $$
     </p>
     <p> We take the sum of the squares of the errors
       $$
       S_r = \sum_{i=0}^{n-1} e_i^2 = \sum_{i=0}^{n-1}(y_i - a_0 - a_1 x_i)^2
       $$
       as our error criterion.
     </p>
   </div>
 </section>
 <section>
  <div class="inner_cell">
   <p> We can find an optimal $a_1$ and $a_0$.
     $$
     a_1 = \frac{n \sum x_i y_i - \sum x_i \sum y_i}{n \sum x_i^2 - (\sum x_i)^2}
     $$
     and 
     $$
     a_0 = \frac{\sum y_i}{n} - a_1 \frac{\sum x_i}{n} = \bar{y} - a_1 \bar{x}
     $$
   </p>
   <p>$\bar{y}$ and $\bar{x}$ are the means of the $x$ and $y$ values.
    $$
    \bar{y} = \frac{1}{N}\sum_{i=0}^{N-1} y_i \qquad \bar{x} = \frac{1}{N}\sum_{i=0}^{N-1} x_i
    $$
  </p>
  <br>
  <p> Correlation of the data: covariance of the data $(x,y)$ divided by the standard deviation of $x$ and $y$.<br><br>
   $$
   r = \frac{n \sum x_i y_i - (\sum x_i)(\sum y_i)}{\sqrt{n \sum x_i^2 - (\sum x_i)^2}\sqrt{n \sum y_i^2 - (\sum y_i)^2}}
   $$
 </p>      
</div>
</section>
</section>

<section>
  <div class="inner_cell">
    <h2 id="Exercises">Exercises<a class="anchor-link" href="#Exercises">&#182;</a></h2>
    <p>Remember in week 1 we looked at finding sums:</p>
    <div style="background-color:Lavender; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left:
    8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;">
    <li> What is $\sum_{n=1}^{100} n$</li>  
    <li> What is $\sum_{n=2}^{200} 2n$</li> 
    <li> What is $\sum_{n=0}^{99} 2n^2$</li>
  </div>

  <p>Now add an extra array into your code and calculate the following:</p>

  <div style="background-color:Lavender; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left:
  8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;">
  <p>$\text{let } x_i = i, i = {1,2,\dots,10}$ and $\text{let } y_i = 2i + 0.3$ for $i = {1,2,\dots,10}$</p>
  <li> What is $\sum_i x_i$</li>  
  <li> What is $\sum_i y_i$</li>
  <li> What is $\sum_i x_i y_i$</li>
  <li> What are $\bar{y}$ and $\bar{x}$</li>
  <li> Find the parameters $a_0$ and $a_1$ for a linear regression model of this data.</li>
</div>
<p> Check your results are correct! I'd suggest using both inspection and Excel.</p>      
</div>
</section>

<section>
  <div class="inner_cell">
    <h2 id="Polynomial Regression">Polynomial Least-squares Regression<a class="anchor-link" href="#Polynomial Regression">&#182;</a></h2>
    <p>We can easily extend our method to deal with polynomicals:
     $$
     y_i = a_0 + a_1 x_i + a_2 x_i^2 + \ldots + a_n x_i^n  + e_i
     $$
   </p>
   <p>and an overall error function
    $$
    S_r = \sum_{i=0}^{N-1} (y_i - a_0 - a_1 x_i - a_2 x_i^2 - \ldots - a_n x_i^n)^2
    $$
  </p>
  <p>We then take partial derivatives with respect to the parameters ($a_0 \ldots a_n$) to get a set of equations.</p>
  <p>Setting these equations equal to zero, writing in matrix form, then solving, gives us the optimal set of parameters.</p>      
</div>
</section>

<section>
  <div class="inner_cell">
    <h3 id="Fitting a Quadratic function">Fitting a Quadratic function<a class="anchor-link" href="#Fitting a Quadratic function">&#182;</a></h3>
    <p>In the case that the largest power of $x$ is $x^2$ we have
     $$
     y_i = a_0 x_i^0 + a_1 x_i^1 + a_2 x_i^2 + e_i
     $$
     and an overall error function
     $$
     S_r = \sum_{i=0}^{N-1} (y_i - a_0 x_i^0 - a_1 x_i^1 - a_2 x_i^2)^2
     $$
   </p>
   <p>This leads to a set of equations
     \begin{align*}
     \left(\sum x_i^0\right) a_0 + \left(\sum x_i^1\right) a_1 + \left(\sum x_i^2\right) a_2 & = \sum x_i^0 y_i \\
     \left(\sum x_i^1\right) a_0 + \left(\sum x_i^2\right) a_1 + \left(\sum x_i^3\right) a_2 & = \sum x_i^1 y_i \\
     \left(\sum x_i^2\right) a_0 + \left(\sum x_i^3\right) a_1 + \left(\sum x_i^4\right) a_2 & = \sum x_i^2 y_i \\
     \end{align*}
   </p>

   <div style="background-color:Lavender; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left:
   8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;">
   <li> Derive the above equations by differentiating $S_r$ with respect to each of the $a_i$ in turn.</li>	
   <li> Write the equations in matrix form $\textbf{A}x = b$, where $x$ is a column matrix with entries $a_0, a_1, a_2$ and $b$ is a column matrix with terms that do not depend on the fitting parameters, $a_0$, $a_1$  and  $a_2$. </li>
   <li>using the data you can find on Blackboard for today's session under the assessments tab.</li>
   <li> Solve for $a_0$, $a_1$  and  $a_2$.</li>
   <li> Plot your fitted parabola against the data to check the fit.</li>
   <li> Extend the derivation to fitting a cubic polynomial and fit to the data on Bb.</li>
 </div>      
</div>           
</section>

<section>
  <div class="inner_cell">
    <h2 id="Multiple Linear Regression">Multiple Linear Regression<a class="anchor-link" href="#Multiple Linear Regression">&#182;</a></h2>
    <p>Instead of powers of a single variable, our model for $y_i$ could be that it is a function of several independent variables:
     $$
     y_i = a_0 + a_1 x_{1i} + a_2 x_{2i} + a_3 x_{3i} + \ldots + a_n x_{ni}
     $$
   </p>

   <div style="background-color:Lavender; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left:
   8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;">
   <li> Derive the a set of equations for the case of two independent variables</li>	
   <li> Write the equations in matrix form $Ax = b$, where $x$ is a column matrix with entries $a_0, a_1, a_2$ </li>
   <p>Using the following data
     $$
     \begin{array} {ccc}
     x_1 & x_2 & y \\
     \hline
     0 & 0 & 5 \\
     2 & 1 & 10 \\
     2.5 & 2 & 9 \\
     1 & 3 & 0 \\
     4 & 6 & 3 \\
     7 & 2 & 27 \\
     \hline
     \end{array}
     $$
   </p>

   <li> Solve for $a_0$, $a_1$  and  $a_2$</li>
   <li> Plot your fitted function against the data to check the fit</li>
 </div>                 
</div>
</section>

<section>
  <div class="inner_cell">
    <h3 id="Linearization of data sets">Linearization of data sets<a class="anchor-link" href="#Linearization of data sets">&#182;</a></h3>
    <p>Multiple Linear Regression is not just limited to obviously linear data.</p>
    <div style="background-color:Lavender; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left:
    8px; padding-right: 8px; padding-top: 8px; border-radius: 25px;">
    <li> How would you apply multiple linear regression to data that you thought was related by $y = a_0 x_1 ^ {a_1} x_2 ^ {a_2} \cdots x_n ^ {a_n}$ ?</li>	
  </div>
</div>
</section>

<section>
  <div class="inner_cell">
    <h2 id="Summary and Further Reading">Summary and Further Reading<a class="anchor-link" href="#Summary and Further Reading">&#182;</a></h2>
    <p>You should be reading additional material to provide a solid background to what we do in class</p>
    <p>Reading: Capra and Canale, introduction to part 5 and chapter 17.</p>
    <p>Lots of details in chapters 14 and 15 of <a href="http://apps.nrbook.com/c/index.html">Numerical Recipes</a>.</p>
  </div>
</section>

</div> <!-- slides -->
</div> <!-- reveal -->

<script>

  require(
  {
      // it makes sense to wait a little bit when you are loading
      // reveal from a cdn in a slow connection environment
      waitSeconds: 15
    },
    [
    "../../../revealjs//lib/js/head.min.js",
    "../../../revealjs//js/reveal.js"
    ],

    function(head, Reveal){

      // Full list of configuration options available here: https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        mouseWheel: false,
        center: false,
        scroll: true,

        // Parallax background image
        parallaxBackgroundImage: 'https://upload.wikimedia.org/wikipedia/commons/2/20/Coloured_Voronoi_2D.svg',
        // Parallax background size
        parallaxBackgroundSize: '2100px 900px', // CSS syntax, e.g. "2100px 900px

        theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
        transition: Reveal.getQueryHash().transition || 'linear', // default/cube/page/concave/zoom/linear/none

        // Optional libraries used to extend on reveal.js
        dependencies: [
        { src: "../../../revealjs//lib/js/classList.js",
        condition: function() { return !document.body.classList; } },
        { src: "../../../revealjs//plugin/notes/notes.js",
        async: true,
        condition: function() { return !!document.body.classList; } }
        ]
      });

      var update = function(event){
        if(MathJax.Hub.getAllJax(Reveal.getCurrentSlide())){
          MathJax.Hub.Rerender(Reveal.getCurrentSlide());
        }
      };

      Reveal.addEventListener('slidechanged', update);

      var update_scroll = function(event){
        $(".reveal").scrollTop(0);
      };

      Reveal.addEventListener('slidechanged', update_scroll);

    }
    );
  </script>

</body>

</html>
